{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Practicalli Engineering Playbook","text":"<p>Quote</p> <p>Effective Communication is the fundamental challenge for all software engineering projects</p> <p>John Stevenson, Practialli</p> <p>The Playbook and Plays concept is used to curate a consistent information, so the right information can be found and used more effectively by all.</p> <ul> <li>A Play is a document that details practices and an approach for a specific task</li> <li>A Playbook is a collection of Plays that are related by topic, e.g. Billie Engineering playbook could cover the practices for deployment, accessing databases, system integration testing, optimising builds in docker.</li> </ul> <p>Engineering Playbook Initiative</p> <p>Establishing a playbook within an organisation encourages information sharing across teams and provides an effective way for disperate teams to learn from each other.</p> <p></p> New Book - content under development <p>Practicalli Engineering Playbook was started in January 2022 in an attempt to codify the last few decades of development experience, so this will be an on-going work</p>"},{"location":"#book-source-code","title":"Book Source code","text":"<p>practicalli/engineering-playbook repository contains the content for this book</p> HTTPSSSH <pre><code>git clone https://github.com/practicalli/engineering-playbook.git\n</code></pre> <pre><code>git clone git@github.com:practicalli/engineering-playbook.git\n</code></pre>"},{"location":"#discussions-and-feedback","title":"Discussions and feedback","text":"<p>Contributions are welcome via GitHub issues and pull requests, or discuss the book on the Clojurians Slack community.</p> <p>Ask questions on #practicalli channel of  Clojurians Slack</p> <p>Get a free Clojurians slack community account</p>"},{"location":"#navigate-the-book","title":"Navigate the book","text":"<p>Use the mouse or built-in key bindings to navigate the pages of the book</p> <ul> <li>P , , : go to previous page</li> <li>N , . : go to next page</li> </ul> <p>Use the search box to quickly find a specific topic</p> <ul> <li>F , S , / : open search dialog</li> <li>Down , Up : select next / previous result</li> <li>Esc , Tab : close search dialog</li> <li>Enter : follow selected result</li> </ul>"},{"location":"#sponsor-my-work","title":"Sponsor my work","text":"<p>All sponsorship recieved is used to maintain and further develop the Practicalli series of books and videos, although most of the work is still done with my own time and cost.</p> <p>Thank you to Cognitect, Nubank and a wide range of other sponsors from the Clojure community for your continued support</p>"},{"location":"#creative-commons-license","title":"Creative commons license","text":"This work is licensed under a Creative Commons Attribution 4.0 ShareAlike License (including images &amp; stylesheets)."},{"location":"architecture/","title":"Architecture tools and techniques","text":"<p>Tools and techniques to support design and communication of archiectural decisions and techniques to elicit archiectural designs</p>"},{"location":"architecture/structurizr/","title":"Structurizr - Architecture diagrams as code","text":"<p>Structurizr is a tool for expressing and visualising architecture using the C4 model</p> <p>Define a single model divided into softwareSystems within which services and persistent data stores are defined. Relationships are defined between services and persistence stores.</p> <p>Many views can be generated from the single model and changes to the model automatically update those views to ensure all views are always up to date.</p> <p></p> <p>Colours of exported SVG image enhanced using Inkscape.org and exported as PNG file</p> <p>Mock Fintech Starup - Practicalli Services practicalli/structurizr Git repository</p>"},{"location":"architecture/structurizr/#c4-model-summary","title":"C4 Model summary","text":"<ul> <li>Level 1: Software system - a system context composed of one or more containers</li> <li>Level 2: Container - application or data store, each component is separately deployable/runable, composed of one or more components</li> <li>Level 3: Component - grouping of functionality with a well defined interface, implemented by one or more code artefacts</li> <li>Level 4: Code - code artefact (function, object/class)</li> </ul> <p>Quick try with Structurizr DSL Editor</p> <p>Structurizr DSL online editor provides an instant way to try structurizr without install or sign-up</p>"},{"location":"architecture/structurizr/#install","title":"Install","text":"<p>Use the free Structurizr Lite locally (via docker) or use Structurizr Cloud service (free for Open Source &amp; Academic projects on request)</p> <p>Project models can be imported into the cloud-based tool from Structurizr Lite when team or company wide collaboration is required.</p> Structurizr liteStructurizr Cloud <p>Structurizr Lite - Getting Started</p> <p>Install Structurizr locally with the free structurizr Lite product via the Docker image. Ensure Docker or Docker Desktop is running  (image approximately 450Mb in size)</p> Docker ComposeDocker <p>Include Structurizr Lite in a <code>docker-compose.yaml</code> file in the root of the project.  Docker compose is especially useful when running one or more services to automatically update views from the model.</p> <p>A volume is use to persist the model <code>workspace.dsl</code> file, enabling local editing of the model while the docker container is running. docker-compose.yaml<pre><code>---\nversion: \"3.9\"\nservices:\n  # --- System Model --- #\n  structurizr:\n    container_name: system-architecture\n    image: \"structurizr/lite:latest\"\nports:\n      - \"8080:8080\"\nvolumes:\n      - \"./model:/usr/local/structurizr:rw\"\n</code></pre></p> <p>Run structurizr lite using the command: <pre><code>docker compose up\n</code></pre></p> <p>Structurizr can also be defined in its own docker compose file and called separately, e.g. <code>strucurizr.yaml</code> configuration file <pre><code>docker compose -f structurizr.yaml up\n</code></pre></p> <p>Pull the docker image</p> <pre><code>docker pull structurizr/lite\n</code></pre> <p>Set the Structurizr project path to define the location of the <code>.dsl</code> or <code>.json</code> workspace definitions (or enter the path directly in the docker command)</p> <p>Practicalli uses the <code>model</code> directory to keep the configuration files</p> <pre><code>export STRUCTURIZR_DATA_PATH=/home/practicalli/projects/practicalli/structurizr/model\n</code></pre> <p>Run docker with the Structurizr data path <pre><code>docker run -it --rm -p 8080:8080 -v $STRUCTURIZR_DATA_PATH:/usr/local/structurizr structurizr/lite\n</code></pre></p> <p> </p> <p><code>workspace.dsl</code> and <code>workspace.json</code> files are created if they do not already exist.</p> <p>Structurizr Cloud</p> <p>Sign up for a free account which provides 1 workspace on the cloud service.</p> Free Cloud product for Open Source &amp; Academic use <p>Access to 5 workspaces on the Structurizr paid cloud service for each open source project or academic     establishment on request</p> <p>Select New workspace after login to Structurizr</p> <p>A summary page of the new workspace is shown, showing the last modified time and an option to load a previous version.</p> <p></p> <p>Scroll the page vertically to see the available diagrams, or click More Diagrams... at the bottom of the page</p>"},{"location":"architecture/structurizr/#structurizr-dsl-editor","title":"Structurizr DSL editor","text":"<p>The model is defined by a domain specific language (DSL) and the DSL editor should be used to add and update all configuration.</p> <p>Select DSL editor from the left hand navigation bar</p> <p>Structurizr DSL Language Reference documentation</p> <p>Select the Source text icon to see only the code window, allowing for easier editing</p>"},{"location":"architecture/structurizr/#define-the-system","title":"Define the system","text":"<p>Structurizr DSL Language Reference documentation Structurizr DSL Cookbook Structurizr DSL online editor</p> <p>The Structurizr DSL online editor is a useful tool to help learn the syntax of the Structurizr DSL, using the Render button to see the results of the model as it is defined.</p> <p>Basic structure:</p> <ul> <li><code>workspace</code> is composed of the system model and views derived from that model</li> <li><code>model</code> is composed of one or more <code>softwaresystems</code></li> <li><code>views</code> define one or more views of the model, using autoLayout to organise diagrams or manually specifying layouts, sytlyes, themes, etc.</li> <li><code>softwaresystem</code> defines specific services along container boundaries (application * data store components)</li> </ul> <p>Add an entry for each service within the specific <code>softwareSystem</code> using the form</p> <pre><code>unique_name_id = container \"Service or data store name\" \"Description of service or database\" \"Container name\" \"View type - Tag name\"\n</code></pre> Tags and themes <p>Tags are used to define the appearance in a view.  Structurizr default theme contains simple tags.  Amazon AWS theme contains a wide range of icons and styles to represent its many services, although these are more suitable for deploymentEnvironment views.  Adding themes section covers this in more detail.</p> <p>For a persistent store, e.g. relational database, use the form</p> <pre><code>fraud_data = container \"Fraud History\" \"A complete history of transactions and reports\" \"fraud-data\" \"database\"\n</code></pre> <p>For an elastic search service, use the form</p> <pre><code>unique_name_id = container \"Display name\" \"Description of service or database\" \"Elastic Search\" \"Elastic\"\n</code></pre> <p>simple example</p> <ul> <li>Create a model with a user and a software system, where the user uses the software system.</li> <li>Create a system context view for the software system, adding the default set of elements, using auto-layout.</li> <li>Use the default theme for styling elements and relationships.</li> </ul> <pre><code>workspace {\n    model {\n        user = person \"User\"\n        softwareSystem = softwareSystem \"Software System\"\n\n        user -&gt; softwareSystem \"Uses\"\n    }\n    views {\n        systemContext softwareSystem \"Diagram1\" {\n            include *\n            autoLayout\n        }\n        theme default\n    }\n}\n</code></pre>"},{"location":"architecture/structurizr/#common-values","title":"Common values","text":"<pre><code>!constant ORGANISATION_NAME \"Practicalli\"\n!constant GROUP_NAME \"Fintech\"\n\nworkspace {\n    model {\n        enterprise \"${ORGANISATION_NAME} - ${GROUP_NAME}\" {\n            user = person \"User\"\n        }\n    }\n}\n</code></pre>"},{"location":"architecture/structurizr/#grouping-services","title":"Grouping services","text":"<p>Grouping services within a softwareSystem keeps closely related service together and are rendered in the group within a view. A group can also be included or excluded from a view</p> <p>The Banking software system contains groups: shared, credit, transaction and fraud. Each group containing a number of services</p> <pre><code>risk = softwareSystem \"Risk\" {\n  shared_services_risk = group \"Shared Services Risk\" {\n    company_info = container \"Company WhoIs\" \"Company search service\" \"Clojure API\"\n    company_info_database = container \"Company WhoIs database\" \"\" \"Relational database schema\" \"Database\"\n    company_info_search = container \"Company Search Aggregator\" \"Company full-text search index\" \"Elastic Search\" \"Elastic\"\n    risk_data_providers = container \"Risk Data Providers\" \"Data Provider Service\" \"PHP Symphony service\"\n    risk_data_providers_database = container \"Risk Data\" \"\" \"Relational database schema\" \"Database\"\n  }\n  credit_risk = group \"Credit Risk\" {\n    score = container \"Credit risk scoring\" \"Scoring organizations Credit Risk\" \"Clojure Service\"\n    score_data = container \"Credit Risk Scoring Service database\" \"\" \"Relational database schema\" \"DatabaseWip\"\n    assessment = container \"Credit Assessment\" \"Credit risk assessment Service\" \"Clojure\"\n  }\n  transaction = group \"Transaction\" {\n    guardian = container \"Transaction Guardian\" \"Transaction monitoring and transaction Screening service\" \"Clojure\"\n    guardian_database = container \"Transaction Guardian Database\" \"\" \"Relational database schema\" \"Database\"\n    limiter = container \"Limiter\" \"Limits Service\" \"ClojureKafka\"\n  }\n  fraud_risk = group \"Fraud Risk\" {\n    detection = container \"Fraud Service\" \"Detect fraudulent transactions via Fraud Scoring Data Science models \" \"Clojure API\"\n    detection_data = container \"Fraud Database\" \"TODO: Define the kind of data persisted\" \"Relational database schema\" \"Database\"\n    ml_model = container \"Machine learning model service\" \"Sagemaker\"\n    feature_store_data = container \"Feature store\" \"Pre-calculated feature values\" \"Key value database\" \"Database\"\n    manual_review = container \"Review Transactions\" \"Manually review transactions for fraud\" \"\" \"WebBrowser\"\n  }\n}\n</code></pre>"},{"location":"architecture/structurizr/#define-relationships","title":"Define relationships","text":"<p><code>-&gt;</code> defines a relationships between two id's defined in the <code>softwareSystem</code> part of the model, along with a description of the relationship that is added to the arrow joining the artefacts in a view.</p> <pre><code>service_name -&gt; service_or_datastore_name \"Description of connection\"\n</code></pre> <p>The relationships are used to draw connections between services and the descriptions name those connections</p> <pre><code>    user -&gt; transaction \"Triggers\"\n\n    transaction -&gt; risk \"Uses\"\n    guardian -&gt; guardian_data \"Persists\"\n    guardian -&gt; limiter \"Uses\"\n\n    detection -&gt; detection_data \"Reads and writes to\"\n    detection -&gt; ml_model \"score transaction\"\n    ml_model -&gt; feature_store_data \"Collect features\"\n    ml_model -&gt; feature_schema_data \"Request feature set &amp; model\"\n</code></pre>"},{"location":"architecture/structurizr/#defining-views","title":"Defining Views","text":"<p>A workspace contains views which visualise artefacts defined in any <code>softwareSystem</code> within the model.</p> <p>A view can include everything * within the softwareSystem or use <code>include</code> and <code>exclude</code> to refine the view based on groups or specific containers.</p> <p>View of the form: view-type softwareSystem-name view-name</p> <p><code>container risk fraud-detection</code></p> <pre><code>container risk \"RiskContainersAfterSE\" {\ninclude *\nautoLayout\n}\ncontainer risk \"CreditRiskServices\" {\ninclude *\nexclude fraud_risk\nautoLayout\n}\ncontainer risk \"FraudServices\" {\ninclude *\nexclude credit_risk\nautoLayout\n</code></pre>"},{"location":"architecture/structurizr/#deployment-infrastructure","title":"Deployment Infrastructure","text":"<p>An example of production deployment environment for the Practicall Mock Fintech Startup</p> <pre><code>  production = deploymentEnvironment \"Production\" {\n    aws = deploymentNode \"Amazon Web Services\" \"\" \"\" \"Amazon Web Services - Cloud\" {\n      region = deploymentNode \"US-East-1\" \"\" \"\" \"Amazon Web Services - Region\" {\n        route53 = infrastructureNode \"Route 53\" \"\" \"\" \"Amazon Web Services - Route 53\"\n        elb = infrastructureNode \"Elastic Load Balancer\" \"\" \"\" \"Amazon Web Services - Elastic Load Balancing\"\n        autoscalingGroup = deploymentNode \"Autoscaling group\" \"\" \"\" \"Amazon Web Services - Auto Scaling\" {\n          ec2 = deploymentNode \"Amazon EC2\" \"\" \"\" \"Amazon Web Services - EC2\" {\n\n            webApplicationInstance = containerInstance detection\n            elb -&gt; webApplicationInstance \"Forwards requests to\" \"HTTPS\"\n          }\n        }\n        rds = deploymentNode \"Amazon RDS\" \"\" \"\" \"Amazon Web Services - RDS\" {\n          mysql = deploymentNode \"MySQL\" \"\" \"\" \"Amazon Web Services - RDS MySQL instance\" {\n            databaseInstance = containerInstance detection_data\n          }\n        }\n        route53 -&gt; elb \"Forward requests to\" \"HTTPS\"\n      }\n    }\n  }\n</code></pre>"},{"location":"architecture/structurizr/#embedding-documentaion-in-views","title":"Embedding Documentaion in views","text":"<p>Create a directory called <code>docs</code> to contain markdown files with system descriptions.</p> <p>Include <code>![](embed:DiagramName)</code> in the markdown file to include the text in the view called <code>DiagramName</code></p> <pre><code>## Context\nHere is a description of my software system...\n\n![](embed:Diagram1)\n</code></pre> <p>The view should be defined in the workspaces.dsl</p> <pre><code>views {\n        systemContext softwareSystem \"DiagramName\" {\n            include *\n            autoLayout\n        }\n</code></pre> Example views from Mock Fintech Startup <p>Views defined in the Practicalli Enterpirse for the Mock Fintech Startup architecture <pre><code>  views {\n   /* Overall system */\n    systemContext risk \"EnterpriseView\" \"Practicalli Enterprise Application\" {\n      include *\n      autoLayout\n    }\n   /* Entire Risk system */\n    container risk riskView \"Complete Risk system\" {\n      include *\n      autoLayout\n    }\n    /* View of shared_services group in risk system */\n    container risk sharedServicesView \"Services shared across the organisation\" {\n      include shared_services\n      autoLayout\n    }\n    /* View of fraud_risk group in risk system */\n    container risk fraudRiskView \"Fraud Risk Services Only\" {\n      include fraud\n      autoLayout\n    }\n    /* View of credit_risk group in risk system */\n    container risk creditRiskView \"Credit Risk Services only\" {\n      include credit\n      autoLayout\n    }\n    /* View of fraud &amp; shared_services group without credit */\n    container risk fraudSharedView \"Fraud and shared services\" {\n      include *\n      exclude credit\n      autoLayout\n    }\n    container transaction transactionView \"Current Transaction system\" {\n      include *\n      autoLayout\n    }\n\n    deployment risk \"Production\" \"AmazonWebServicesDeployment\" {\n      include *\n      autolayout lr\n      animation {\n        route53\n        elb\n        autoscalingGroup\n        webApplicationInstance\n        databaseInstance\n      }\n    }\n\n    /* Theme for views */\n    themes default https://static.structurizr.com/themes/amazon-web-services-2022.04.30/theme.json https://raw.githubusercontent.com/practicalli/structurizr/main/themes/practicalli/theme.json\n\n    branding {\n      logo https://raw.githubusercontent.com/practicalli/graphic-design/live/logos/practicalli-logo.png\n    }\n  }\n</code></pre></p>"},{"location":"architecture/structurizr/#adding-themes","title":"Adding themes","text":"<p>Themes add styles or icons to the diagrams rendered by Structurizr tools, e.g. Amazon AWS icons.</p> <p>Add a theme to the workspace.dsl configuration and add a theme tag to a component definition.</p> <p><code>theme</code> key is added as a value within the <code>views</code> key of the <code>workspace</code>.  <code>themes</code> is used to include multiple themes.</p> <p>Structurizr language reference - theme</p> <p>Example: using the Amazon icons</p> <pre><code>    views {\n        systemContext softwareSystem \"Diagram1\" {\n            include *\n            autoLayout\n        }\n        theme https://static.structurizr.com/themes/amazon-web-services-2022.04.30/theme.json\n    }\n</code></pre> <p>Use icons from the theme by adding one of the theme tags</p> <pre><code>identifier = type \"\" \"\" \"\" \"tag-name\"\n</code></pre> <p>Exmaple: the <code>\"Amazon Web Services - SageMaker\"</code> tag is added to a machine learning model</p> <pre><code>ml_model = container \"AWS Sagemaker\" \"Machine learning model service\" \"\" \"Amazon Web Services - SageMaker\"\n</code></pre> Useful Amazon Web Services Tags <p>Amazon Web Services theme - tags commonly used:</p> <ul> <li>Amazon Web Services - Lambda</li> <li>Amazon Web Services - Fargate</li> <li>Amazon Web Services - Route 53</li> <li>Amazon Web Services - Simple Storage Service</li> <li>Amazon Web Services - EC2</li> <li>Amazon Web Services - EC2 AMI</li> <li>Amazon Web Services - EC2 Auto Scaling</li> <li>Amazon Web Services - Elastic Load Balancing</li> <li>Amazon Web Services - Elastic Container Service</li> <li>Amazon Web Services - Elastic Container Kubernetes</li> <li>Amazon Web Services - Elastic Container Registry</li> <li>Amazon Web Services - Elastic Container Registry Image</li> <li>Amazon Web Services - EKS Cloud</li> <li>Amazon Web Services - Elastic Beanstalk</li> <li>Amazon Web Services - Category Database</li> <li>Amazon Web Services - Category Machine Learning</li> <li>Amazon Web Services - Category Serverless</li> <li>Amazon Web Services - Corretto</li> <li>Amazon Web Services - Data Pipeline</li> <li>Amazon Web Services - Deep Learning Containers</li> <li>Amazon Web Services - RDS</li> <li>Amazon Web Services - DocumentDB</li> <li>Amazon Web Services - DynamoDB</li> <li>Amazon Web Services - Managed Service for Grafana</li> <li>Amazon Web Services - Managed Service for Prometheus</li> <li>Amazon Web Services - Managed Streaming for Apache Kafka</li> <li>Amazon Web Services - Managed Workflows for Apache Airflow</li> <li>Amazon Web Services - Secrets Manager</li> <li>Amazon Web Services - Single Sign On</li> <li>Amazon Web Services - Virtual Private Cloud</li> </ul>"},{"location":"architecture/structurizr/#custom-theme","title":"Custom Theme","text":"<p>Create a theme as a <code>.json</code> file that containes a collection of definitions within <code>\"elements\": [ ]</code></p> <p>Each element should define the <code>\"tag\"</code> name used in the view definition to identify the type of element to use.</p> <p>The look of the element is defined by <code>\"colour\"</code>, <code>\"background\"</code>, <code>\"stroke\"</code> hex color values and a <code>\"shape\"</code> type, e.g. <code>\"RoundedBox\"</code>, <code>\"Cylinder\"</code></p> <p>Include an <code>\"icon\"</code> as a further visual representation of the element, e.g. using AWS theme icons.</p> <p>Element style DSL reference Practicalli Structurizr theme</p> Practicalli Custom theme and AWS theme practicalli/structurizr theme/practicalli/theme.json<pre><code>{\n  \"name\" : \"Practicalli theme\",\n  \"elements\" : [ {\n    \"tag\" : \"Clojure Service\",\n    \"background\" : \"#8FB5FE\",\n    \"color\" : \"#EEECE6\",\n    \"stroke\" : \"#5881D8\",\n    \"shape\" : \"RoundedBox\",\n    \"icon\" : \"https://raw.githubusercontent.com/practicalli/graphic-design/live/logos/clojure-logo-64.png\"\n  } , {\n    \"tag\" : \"Database\",\n    \"background\" : \"#EEECE6\",\n    \"color\" : \"#3f51d4\",\n    \"stroke\" : \"#3f51d4\",\n    \"shape\" : \"Cylinder\",\n    \"icon\" : \"https://static.structurizr.com/themes/amazon-web-services-2022.04.30/Arch_Amazon-RDS_48.png\"\n  } , {\n    \"tag\" : \"Web Browser\",\n    \"shape\" : \"WebBrowser\"\n  } , {\n    \"tag\" : \"AWS SageMaker\",\n    \"background\" : \"#EEECE6\",\n    \"stroke\" : \"#2d8f7a\",\n    \"color\" : \"#2d8f7a\",\n    \"icon\" : \"https://static.structurizr.com/themes/amazon-web-services-2022.04.30/Arch_Amazon-SageMaker_48.png\"\n  } ]\n}\n</code></pre> <p>Practicalli Structurizr theme provides <code>Clojure Service</code>, <code>Database</code>, <code>Web Browser</code> and <code>AWS SageMaker</code> tags to customise the views generated.</p> <p>The <code>Database</code> tag uses the icon from the AWS theme, although changes colors and shape to improve readability of the diagrams. The <code>AWS SageMaker</code> tag overrides that provided by AWS theme, again improving the readability of the diagrams.</p> <p>The Mock Fintect Startup example uses a custom theme by Practicalli and the standard AWS theme.  It also includes the Practicalli Logo that appears next to the name of the view in each diagram</p> practicalli/structurizr model/workspace.dsl extract<pre><code>themes default https://static.structurizr.com/themes/amazon-web-services-2022.04.30/theme.json https://raw.githubusercontent.com/practicalli/structurizr/main/themes/practicalli/theme.json\n\nbranding {\n  logo https://raw.githubusercontent.com/practicalli/graphic-design/live/logos/practicalli-logo.png\n}\n</code></pre>"},{"location":"architecture/structurizr/#organisation-branding","title":"Organisation branding","text":"<p>Add a PNG or Jpeg graphic as a logo on all diagrams, appearing in the bottom left of each page</p> <p>Define a specific font to use for all text in the digram (font downloaded from Google Fonts)</p> <p>Define a <code>branding</code> section in the workspace &gt; views section of the <code>workspace.dsl</code> file.</p> <pre><code>branding {\n    logo &lt;file|url&gt;\n    font &lt;name&gt; [url]\n}\n</code></pre> <p>Practicalli uses the following branding in the structurizr <code>workspace.dsl</code></p> practicalli/structurizr model/workspace.dsl extract<pre><code>branding {\n  logo https://raw.githubusercontent.com/practicalli/graphic-design/live/logos/practicalli-logo.png\n}\n</code></pre>"},{"location":"architecture/structurizr/#comments","title":"Comments","text":"<p><code>/* */</code> for line comments.</p> <pre><code>/* single-line comment */\n/*\n    multi-line comment\n*/\n</code></pre> <p>Note: line comments within parens or directly after a closing paren cause syntax error</p>"},{"location":"architecture/structurizr/#practicalli-system","title":"Practicalli System","text":"<p>The Practicalli Mock Fintech Startup is defined as workspace that contains a model with an enterprise \"Practicalli\" key defining the high-level software systems</p> <ul> <li>Credit Assesment</li> <li>Risk Analysis</li> <li>Transactions (credit card, National bank deposit/transfer, BACS)</li> <li>Shared Services (account management, etc)</li> </ul> <p>A simple mock up of a Fintech managing transactions that may be susceptible to various risks, including fraud</p> <p>Practicalli Structurizr project - Mock Fintech Startup</p> <p><code>workspace.dsl</code> defined a Practicalli Enterprise with several softwareSystem defintions, each representing aspects of the business</p> <p>Each softwareSystem is composed of containers that represent a logical service and related containers are grouped together</p> <p>Relationships between containers are defined, stating the direction and relationship name, represented as arrows in the model views</p> <p><code>workspace.dsl</code> also contains a deploymentEnvironment for production, defining the infrastructure that containers are deployed into</p> <p>A range of views are defined, using include and exclude options to refine the containers that are shown</p> <p>Practicalli Structurizr custom theme and AWS theme are included, along with Practicalli logo in the branding</p>"},{"location":"architecture/structurizr/#resources","title":"Resources","text":"<ul> <li>Diagrams as Code 2.0 - Simon Brown, 2021.</li> <li>Getting started with Structurizr Lite - Simon Brown, 2021</li> <li>Structurizr DSL: AWS Example deployment</li> <li>Structurizr DSL: Big Bank</li> <li>Structurizr/dsl code examples</li> <li>Model example: Amazon Web Services local</li> </ul>"},{"location":"assets/images/social/","title":"Social Cards","text":"<p>Social Cards are visual previews of the website that are included when sending links via social media platforms.</p> <p>Material for MkDocs is configured to generate beautiful social cards automatically, using the colors, fonts and logos defined in <code>mkdocs.yml</code></p> <p>Generated images are stored in this directory.</p>"},{"location":"build-tool/","title":"Build Tools","text":"<p>Build tools can support a wide range of development tasks</p> <ul> <li>GNU make - language agnostic build tool, define any tasks</li> <li>babashka - write a built tool using Clojure</li> </ul>"},{"location":"build-tool/babashka-task-runner/","title":"Babashka Task Runner","text":"<p>Babashka is a scripting tool that runs Clojure code.</p> <p>Babashka provides a task runner which can be used as a basis for creating a build tool</p> <p> Babashka Task Runner</p>"},{"location":"build-tool/make/","title":"Make","text":"<p>GNU Make provide a simple and consistent way to run any development task for Clojure &amp; ClojureScript projects (or any other languages).</p> <p>Wrap any combination of tools (building, linting, formatting, testing) with make targets for a simple command line interface, with automatically tab completion, making any Clojure project really easy to work with.  Practicalli also uses make to manage docker images and containers to support Clojure development.</p> <p>All that is required is a  <code>Makefile</code> in the root of the project</p> Practicalli Makefile for Clojure projects .github/config/megalinter.yaml<pre><code># ------------------------------------------\n# Makefile: Clojure Service\n#\n# Consistent set of targets to support local development of Clojure\n# and build the Clojure service during CI deployment\n#\n# Requirements\n# - cljstyle\n# - Clojure CLI aliases\n#   - `:env/dev` to include `dev` directory on class path\n#   - `:env/test` to include `test` directory and libraries to support testing\n#   - `:test/run` to run kaocha kaocha test runner and supporting paths and dependencies\n#   - `:repl/rebel` to start a Rebel terminal UI\n#   - `:package/uberjar` to create an uberjar for the service\n# - docker\n# - mega-linter-runner\n#\n# ------------------------------------------\n# .PHONY: ensures target used rather than matching file name\n# https://makefiletutorial.com/#phony\n.PHONY: all lint deps dist pre-commit-check repl test test-ci test-watch clean\n# ------- Makefile Variables --------- #\n# run help if no target specified\n.DEFAULT_GOAL := help\n# Column the target description is printed from\nHELP-DESCRIPTION-SPACING := 24\n# Makefile file and directory name wildcard\n# EDN-FILES := $(wildcard *.edn)\n# ------------------------------------ #\n# ------- Help ----------------------- #\n# Source: https://nedbatchelder.com/blog/201804/makefile_help_target.html\nhelp:  ## Describe available tasks in Makefile\n@grep '^[a-zA-Z]' $(MAKEFILE_LIST) | \\\nsort | \\\nawk -F ':.*?## ' 'NF==2 {printf \"\\033[36m  %-$(HELP-DESCRIPTION-SPACING)s\\033[0m %s\\n\", $$1, $$2}'\n# ------------------------------------ #\n# ------- Clojure Development -------- #\nrepl:  ## Run Clojure REPL with rich terminal UI (Rebel Readline)\n$(info --------- Run Rebel REPL ---------)\nclojure -M:test/env:repl/reloaded\ndeps: deps.edn  ## Prepare dependencies for test and dist targets\n$(info --------- Download test and service libraries ---------)\nclojure -P -X:build\ndist: build-uberjar ## Build and package Clojure service\n$(info --------- Build and Package Clojure service ---------)\n# Remove files and directories after build tasks\n# `-` before the command ignores any errors returned\nclean:  ## Clean build temporary files\n$(info --------- Clean Clojure classpath cache ---------)\n- rm -rf ./.cpcache\n# ------------------------------------ #\n# ------- Testing -------------------- #\ntest-config:  ## Print Kaocha test runner configuration\n$(info --------- Runner Configuration ---------)\nclojure -M:test/env:test/run --print-config\ntest-profile:  ## Profile unit test speed, showing 3 slowest tests\n$(info --------- Runner Profile Tests ---------)\nclojure -M:test/env:test/run --plugin  kaocha.plugin/profiling\ntest:  ## Run unit tests - stoping on first error\n$(info --------- Runner for unit tests ---------)\nclojure -X:test/env:test/run\ntest-all:  ## Run all unit tests regardless of failing tests\n$(info --------- Runner for all unit tests ---------)\nclojure -X:test/env:test/run :fail-fast? false\ntest-watch:  ## Run tests when changes saved, stopping test run on first error\n$(info --------- Watcher for unit tests ---------)\nclojure -X:test/env:test/run :watch? true\ntest-watch-all:  ## Run all tests when changes saved, regardless of failing tests\n$(info --------- Watcher for unit tests ---------)\nclojure -X:test/env:test/run :fail-fast? false :watch? true\n# ------------------------------------ #\n# -------- Build tasks --------------- #\nbuild-config: ## Pretty print build configuration\n$(info --------- View current build config ---------)\nclojure -T:build config\nbuild-jar: ## Build a jar archive of Clojure project\n$(info --------- Build library jar ---------)\nclojure -T:build jar\nbuild-uberjar: ## Build a uberjar archive of Clojure project &amp; Clojure runtime\n$(info --------- Build service Uberjar  ---------)\nclojure -T:build uberjar\nbuild-clean: ## Clean build assets or given directory\n$(info --------- Clean Build  ---------)\nclojure -T:build clean\n# ------------------------------------ #\n# ------- Code Quality --------------- #\npre-commit-check: format-check lint test  ## Run format, lint and test targets\nformat-check: ## Run cljstyle to check the formatting of Clojure code\n$(info --------- cljstyle Runner ---------)\ncljstyle check\nformat-fix:  ## Run cljstyle and fix the formatting of Clojure code\n$(info --------- cljstyle Runner ---------)\ncljstyle fix\nlint:  ## Run MegaLinter with custom configuration (node.js required)\n$(info --------- MegaLinter Runner ---------)\nnpx mega-linter-runner --flavor java --env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\" --remove-container\nlint-fix:  ## Run MegaLinter with applied fixes and custom configuration (node.js required)\n$(info --------- MegaLinter Runner ---------)\nnpx mega-linter-runner --fix --flavor java --env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\" --remove-container\nlint-clean:  ## Clean MegaLinter report information\n$(info --------- MegaLinter Clean Reports ---------)\n- rm -rf ./megalinter-reports\n# ------------------------------------ #\n# ------- Docker Containers ---------- #\ndocker-build:  ## Build Clojure project and run with docker compose\n$(info --------- Docker Compose Build ---------)\ndocker compose up --build --detach\ndocker-build-clean:  ## Build Clojure project and run with docker compose, removing orphans\n$(info --------- Docker Compose Build - remove orphans ---------)\ndocker compose up --build --remove-orphans --detach\ndocker-down:  ## Shut down containers in docker compose\n$(info --------- Docker Compose Down ---------)\ndocker compose down\nswagger-editor:  ## Start Swagger Editor in Docker\n$(info --------- Run Swagger Editor at locahost:8282 ---------)\ndocker compose -f swagger-editor.yml up -d swagger-editor\nswagger-editor-down:  ## Stop Swagger Editor in Docker\n$(info --------- Run Swagger Editor at locahost:8282 ---------)\ndocker compose -f swagger-editor.yml down\n# ------------------------------------ #\n# ------ Continuous Integration ------ #\n# .DELETE_ON_ERROR: halts if command returns non-zero exit status\n# https://makefiletutorial.com/#delete_on_error\ntest-ci: deps  ## Test runner for integration tests\n$(info --------- Runner for integration tests ---------)\nclojure -P -X:test/env:test/run\n# Run tests, build &amp; package the Clojure code and clean up afterward\n# `make all` used in Docker builder stage\n.DELETE_ON_ERROR:\nall: test-ci dist clean  ## Call test-ci dist and clean targets, used for CI\n</code></pre>"},{"location":"build-tool/make/#gnu-make-overview","title":"GNU Make overview","text":"<p>GNU Make is a programming language agnostic build automation tool which has been an integral part of building Linux/Unix operating system code and applications for decades, providing a consistent way to configure, compile and deploy code for all projects.</p> <p>A <code>Makefile</code> defines targets called via the <code>make</code> command. Each target can run one or more commands.  Targets can be dependent on other targets,  e.g the <code>dist</code> target that builds a project can be dependent on <code>deps</code> &amp; <code>test</code> targets.</p> <p>GNU Make is available on all Linux/Unix based operating systems (and Windows via chocolatey or nmake).</p> <p>Practicalli also uses <code>make</code> to configure and build the latest versions of Emacs and other Linux open source software</p>"},{"location":"build-tool/make/#defining-tasks","title":"Defining tasks","text":"<p>Create a <code>Makefile</code> in the root of a project and define a target by typing a suitable name followed by a <code>:</code> character, e.g. <code>test:</code></p> <p>Insert a tab on the next line and type a command to be called.  Further commands can be added on new lines so long as each line is tab indented.</p> <p>The <code>repl</code> target prints out an information message and then uses the Clojure CLI with aliases from Practicalli Clojure CLI Config to run a Clojure REPL process with a rich terminal UI (Rebel Readline)</p> <pre><code>repl:  ## Run Clojure REPL with rich terminal UI (Rebel Readline)\n$(info --------- Run Rebel REPL ---------)\nclojure -M:env/dev:env/test:repl/rebel\n</code></pre>"},{"location":"build-tool/make/#common-target-naming","title":"Common target naming","text":"<p>Targets used across Practicalli projects follow the make standard targets for users</p> <p><code>all</code> , <code>test-ci</code> , <code>deps</code> and <code>dist</code> targets are recommended for use with a CI deployment pipeline and builder stage when using Docker.</p> <ul> <li><code>all</code>  calling all targets to prepare the application to be run. e.g. all: deps test-ci dist clean</li> <li><code>deps</code> download library dependencies (depend on <code>deps.edn</code> file)</li> <li><code>dist</code> create a distribution tar file for this program or zip deployment package for AWS Lambda</li> <li><code>lint</code> run lint tools to check code quality  - e.g MegaLinter which provides a wide range of tools</li> <li><code>format-check</code> report format and style issues for a specific programming language</li> <li><code>format-fix</code> update source code files if there are format and style issues for a specific programming language</li> <li><code>pre-commit</code> run unit tests and code quality targets before considering a Git commit</li> <li><code>repl</code> run an interactive run-time environment for the programming language</li> <li><code>test-unit</code> run all unit tests</li> <li><code>test-ci</code> test running in CI build (optionally focus on integration testing)</li> <li><code>clean</code> remove files created by any of the commands from other targets (i.e. ensure a clean build each time)</li> </ul> <p> practicalli/dotfiles/Makefile also defines docker targets to build and compose images locally, inspect images and prune containers and images.</p>"},{"location":"build-tool/make/#target-dependencies","title":"Target dependencies","text":"<p>A <code>Makefile</code> target can depend on either a file name or another target in the <code>Makefile</code>.</p> <p>The all target typically depends on several <code>Makefile</code> targets to test, compile and package a service.  Add the names of the targets this target depends upon</p> <pre><code>all: deps test-ci dist clean\n</code></pre> <p>Add the filename of a file after the name of the target, to depend on if that file has changed.  If the file has not changed since make was last run then the task will not run again.</p> <p>Clojure CLI Example: If the <code>deps</code> target depends on <code>deps.edn</code> and the file has not changed since last run, the deps target will not run again.</p>"},{"location":"build-tool/make/#deps-target-depend-on-a-file","title":"deps target - depend on a file","text":"<p>The deps target would use Clojure CLI or Leiningen to download dependencies.</p> <p>Configuring the <code>deps</code> target to depend on <code>deps.edn</code> or <code>project.clj</code> file, then if the file has not changed the deps will not run again.</p> <p>A Clojure CLI example depends on the <code>deps.edn</code> file that defines all the library dependencies for the project, tools for testing and packaging the Clojure service.  The <code>-P</code> flag is the prepare option, a dry run that only downloads the dependencies for the given tasks.</p> <pre><code>deps: deps.edn  ## Prepare dependencies for test and dist targets\n$(info --------- Download libraries to test and build the service ---------)\nclojure -P -X:env/test:package/uberjar\n</code></pre> <p><code>:env/test</code> adds libraries to run Kaocha and libraries used to run unit tests.  <code>:package/uberjar</code> runs a tool that creates an uberjar.</p>"},{"location":"build-tool/make/#clean-target-hiding-command-failure","title":"Clean target - hiding command failure","text":"<p>The clean target should remove files and directories created by the build (compile) process, to ensure a consistent approach to building each time.</p> <p>On Linux / Unix systems files can be deleted with the <code>rm</code> command using <code>-r</code> for recursively deleting a directory and its contents. <code>-f</code> forces the deleting of files and directories, otherwise a prompt for confirmation of the delete may be shown.</p> <p><code>-</code> before a command  instructs <code>make</code> to ignore an error code, useful if the files to be deleted did not exist (i.e. the build failed part way through and not all files were created).</p> <pre><code># `-` before the command ignores any errors returned\nclean:\n$(info --------- Clean Clojure classpath cache ---------)\n- rm -rf ./.cpcache\n</code></pre>"},{"location":"build-tool/make/#megalinter-target-simplifying-a-command","title":"MegaLinter target - simplifying a command","text":"<p>The <code>lint</code> target is an example of how the <code>Makefile</code> simplifies the command line interface.</p> <p><code>lint:</code> target is used to call the MegaLinter runner, avoiding the need to remember the common options passed when calling MegaLinter command line tool, <code>mega-linter-runner</code></p> <p>The Java flavor of MegaLinter is less than 2Gb image (full MegaLinter image is 8Gb) and contains all the tools for a Clojure project.  The flavor can only be set via a command line option, so the make file ensures that option is always used and the full MegaLinter docker image is not downloaded by mistake.</p> <p>When MegaLinter is configured to generate reports (default), <code>lint-clean:</code> target is used to clean those reports.</p> <pre><code># Run MegaLinter with custom configuration\nlint:\n$(info --------- MegaLinter Runner ---------)\nmega-linter-runner --flavor java --env 'MEGALINTER_CONFIG=.github/linters/mega-linter.yml'\nlint-clean:\n$(info --------- MegaLinter Clean Reports ---------)\n- rm -rf ./megalinter-reports\n</code></pre>"},{"location":"build-tool/make/#enhancing-make-output","title":"Enhancing make output","text":"<p>The <code>info</code> message is used with each target to enhances the readability of the make output, especially when multiple targets and commands are involved, or if commands are generating excessive output to standard out.</p> <pre><code> test:\n    $(info --------- Runner for unit tests ---------)\n./bin/test\n</code></pre> <p></p>"},{"location":"build-tool/make/#avoiding-file-name-collisions","title":"Avoiding file name collisions","text":"<p>Although unlikely, if a filename in the root of a project has the same name as a <code>Makefile</code> target, it can be used instead of running the targets command</p> <p><code>.PHONY:</code> defines the names of targets in the <code>Makefile</code> to avoid name clashes</p> <pre><code>.PHONY: all lint deps test test-ci dist clean\n</code></pre> <p>Reference:  Makefile Tutorial: phony</p>"},{"location":"build-tool/make/#halt-on-failure","title":"Halt on failure","text":"<p><code>.DELETE_ON_ERROR:</code> halts any further commands if a command returns non-zero exit status.  Useful as short-circuit to stop tasks when further work is not valuable, e.g. if tests fail then it may not be valuable to build the Clojure project.</p> <pre><code>.DELETE_ON_ERROR:\nall: deps test-ci dist clean\n</code></pre> <p>Reference:  Makefile Tutorial:  delete_on_error</p>"},{"location":"build-tool/make/#references","title":"References","text":"<p> Makefile Tutorial by Example  practicalli/dotfiles Makefile</p>"},{"location":"build-tool/make/#summary","title":"Summary","text":"<p>A <code>Makefile</code> can simplify the command line interface for any task with a Clojure project (or any other language and tooling).</p> <p>Using the same target names across all projects reduces the cognitive load for driving any project.</p>"},{"location":"code-quality/","title":"Code Quality","text":"<p>Tools can provide a base level of code quality and consistency when developing locally.</p> <p>Those same tools can check important quality rules when sharing code via continuous integration workflows, focusing the scope of code reviews on the more valuable aspect of design decisions</p> <ul> <li>Lint tools identify syntax and formatting issues for a specific programming language or configuration file</li> <li>Format tools ensures code follows a common set of format and indent rules</li> </ul> <p>The development team should agree on the rules that are valueable for these tools to apply, including those recommended by the community around the programming language or configuration file specification.</p>"},{"location":"code-quality/#recommended-tools","title":"Recommended Tools","text":"<p>MegaLinter provides an extensive range of lint tools all in one, using docker images to remove tool installation requirements.</p> <p>MegaLinter - extensive collection of lint tools</p> <p>Clojure Quality Tools</p>"},{"location":"code-quality/clojure/","title":"Clojure Quality tools","text":""},{"location":"code-quality/clojure/#syntax-idiom-check","title":"Syntax &amp; Idiom check","text":"<p>clj-kondo is a lint tool that highlights syntactic errors and suggests idioms for Clojure, ClojureScript and EDN.</p> <p>Use clj-kondo with your preferred editor to warning about errors as you type so issues can be fixed as soon as they occur, enhancing your joy of Clojure.</p> <p>clj-kondo can also be used as a command line tool for checking projects in development environments and continuous integration service, such as the setup-clojure GitHub action.</p> <p>Clojure LSP includes clj-kondo</p> <p>Clojure LSP install includes clj-kondo, removing the need for a separate install of clj-kondo</p> <p>clj-kondo install guide</p> <p>Clj-kondo config contains additional configuration for using clj-kondo with libraries that extend the Clojure language via macros.</p>"},{"location":"code-quality/clojure/#command-line","title":"Command Line","text":"<p>Run <code>clj-kondo</code> with the --lint option and specify a file or path</p> <p>To analyse a specific file</p> <pre><code>clj-kondo --lint ~/.config/deps.edn\n</code></pre> <p>Analyse a project, running the clj-kondo command from the root of the project</p> <pre><code>clj-kondo --lint .\n</code></pre>"},{"location":"code-quality/clojure/#github-workflow","title":"GitHub workflow","text":"<p>Add clj-kondo linting to continuous integration workflow checks for syntax errors with Clojure files.</p> <p>Setup Clojure Clojure Lint &amp; Reviewdog Setup clj-kondo</p> <p>Setup Clojure with clj-kondo and cljstyle checks</p> <pre><code>---\nname: \"Quality Checks\"\non:\npull_request:\npush:\nbranches:\n- live\njobs:\ntests:\nname: \"Check Code Quality\"\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n- name: \"Checkout code\"\nuses: actions/checkout@v3.3.0\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n- name: \"Install tools\"\nuses: DeLaGuardo/setup-clojure@10.1\nwith:\ncljstyle: 0.15.0\nclj-kondo: 2022.11.02\n- name: \"Lint Clojure\"\nrun: clj-kondo --lint deps.edn --config '{:output {:pattern \"::{{level}} file={{filename}},line={{row}},col={{col}}::{{message}}\"}}'\n- name: \"Check Clojure Style\"\nrun: cljstyle check --report\n- run: echo \"\ud83c\udfa8 style and format of Clojure code checked\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre> Setup clojure-lsp Action <p>Setup Clojure-LSP contains clj-kondo so can also be used within a continuous integration workflow as well as provide .</p>"},{"location":"code-quality/clojure/#format-check-and-fix","title":"Format Check and Fix","text":"<p>Code is easier to read and work with when it is consistent format that follows common rules.</p> <p>Clojure community style guide provides a common style for Clojure code.  While most style recommendations are widely used, others are more contentious.  Ultimately the development team for the project should define a workable set of style rules that makes them productions, ideally using much of those rules from the style guide.</p> <p>A consistent format between editors also minimises version control changes not related to code design.  The following format tools for clojure can all be configured to be consistent with each other (although zprint defaults will require more customisation):</p> <ul> <li>cljfmt - library, also included in Clojure LSP</li> <li>cljstyle - binary and library (re-write of cljfmt)</li> <li>zprint - binary &amp; library</li> </ul> Tooling that uses the Clojure Style Guide <p>Emacs <code>clojure-mode</code> and Clojure LSP (via cljfmt) format code following the most common Clojure style guide rules, although cljfmt rules are quite strick so Practicalli disables many of them.</p> <p>cljstyle default configuration follows the majority of styles and has the same defaults as cljfmt. Practicalli Clojure CLI Config tweaks a few rules to make code more readable and allow for repl design experiments.</p>"},{"location":"code-quality/clojure/#cljstyle","title":"cljstyle","text":"<p>Cljstyle is a rewrite of cljfmt, designed to be easier to configure. The default rules implement many of the style rules from the Clojure community style guide and is compatible with cljfmt.</p> <p>Call with the <code>check</code> option to report formatting issues, providing a coloured diff view of the format changes</p> <p> </p> <p>Call with <code>fix</code> option to automatically update all Clojure files with fixes, indicating which files have changed.</p> <p>Cljstyle will examine all files in the current directory and any sub-directories.</p> <p><code>.cljstyle</code> configuration file in the root of the project can override the default customisation, including indentation rules.</p> <p>cljstyle config used by Practicalli</p> <p>Clojure App template repository contains the <code>.cljstyle</code> configuration file used for all Practicalli projects</p> BinaryPracticalli Clojure CLI ConfigMakefile <p>Install the latest binary release from the cljstyle GitHub repository onto the operating system path, e.g. <code>$HOME/.local/bin</code></p> <pre><code>cljstyle check\n</code></pre> <p><code>fix</code> option automatically updates all source code files that have format issues.</p> <pre><code>cljstyle fix\n</code></pre> <p>cljstyle can be used as a library without installing the cljstyle binary.  Practicalli Clojure CLI Config defines the <code>:format/cljstyle</code> alias which should be passed wither the <code>check</code> or <code>format</code> option</p> <p>Check all the Clojure files (.clj .cljc .edn .cljs) in the current project <pre><code>clojure -M:format/cljstyle\n</code></pre></p> <pre><code>clojure -M:format/cljstyle!\n</code></pre> <p>Clojure Alias for cljstyle</p> <pre><code>:format/cljstyle\n{:extra-deps\n{mvxcvi/cljstyle {:git/url \"https://github.com/greglook/cljstyle.git\"\n:git/sha \"14c18e5b593c39bc59f10df1b894c31a0020dc49\"}}\n:main-opts [\"-m\" \"cljstyle.main\" \"check\"]}\n:format/cljstyle!\n{:extra-deps\n{mvxcvi/cljstyle {:git/url \"https://github.com/greglook/cljstyle.git\"\n:git/sha \"14c18e5b593c39bc59f10df1b894c31a0020dc49\"}}\n:main-opts [\"-m\" \"cljstyle.main\" \"fix\"]}\n</code></pre> <p>Use a Makefile to run common commands such as checking style, running tests, building uberjars, etc.</p> <p>Practicalli Clojure App template repository contains an example Makefile that contains common tasks for Clojure development</p> <p>This example calls the cljstyle binary, but could be changed to call the <code>clojure -M:format/cljstyle check</code> and <code>clojure -M:format/cljstyle fix</code> aliases instead.</p> <pre><code># ------- Code Quality --------------- #\nformat-check: ## Run cljstyle to check the formatting of Clojure code\n$(info --------- cljstyle Runner ---------)\ncljstyle check\n\nformat-fix:  ## Run cljstyle and fix the formatting of Clojure code\n$(info --------- cljstyle Runner ---------)\ncljstyle fix\n# ------------------------------------ #\n</code></pre> <p>Stage changes before automatically fixing format</p> <p>Practicalli suggests staging (or committing) changes before running <code>cljstyle fix</code> to easily undo undesired changes or simply confirm what changes have been made</p> <p>Practicall configuration</p> <p>Practicalli updated the default cljstyle configuration with the following changes</p> <p>Configure list indent to one character</p> .cljstyle<pre><code>  :indentation\n{:enabled? true,\n   :list-indent 1,\n\n}\n</code></pre> <p>Do not warn about duplicate var names (def, defn names) - excluded to stop warning about REPL experiments and design journal rich comments that contain alternative designs.</p> .cljstyle<pre><code>  :vars\n{:enabled? false}\n</code></pre>"},{"location":"code-quality/clojure/#cljfmt","title":"cljfmt","text":"<p>cljfmt is not available as a separate binary, although it a fixed part of the Clojure LSP server implementation.</p> <p>whist typing Clojure code, Clojure LSP will format using cljfmt rules</p> <p>Define a cljfmt configuration via Clojure LSP to define rules and indentation settings for all projects.</p> .config/clojure-lsp/config.edn<pre><code> :cljfmt-config-path \"cljfmt.edn\"\n</code></pre> <p>Or specify cljfmt configuration within the Clojure LSP configuration file</p> .config/clojure-lsp/config.edn<pre><code> :cljfmt {}\n</code></pre> Practicalli Clojure LSP config - LSP and cljfmt <p>Practicalli Clojure LSP config provides an example config.edn configuration file for Clojure LSP that uses a cljfmt.edn configuration file for a minimum set of Clojure format rules</p> <p>The default cljfmt rules feel overly strict and Practicalli configuration disables the more draconian rules to make code far more readable</p>"},{"location":"code-quality/clojure/#zprint","title":"zprint","text":"<p>zprint is a highly configurable format tool for both Clojure code and Clojure/EDN structures, available as a library and command line tool</p> <p>zprint has advanced features over cljstyle and cljfmt, although may require some additional configuration work especially to format consistently with these tools.</p> <p>zprint available styles</p> No built-in diff option <p>zprint requires an external diff tool to see the format changes made, as zprint only reports on the files changed and not the content of those files that has changed.</p> <p>zprint can write changes to a new file and a file comparison made.  Or files can be staged / committed in a local Git repository before running zprint and a Git client used to see the diff.</p> <p>Once the desirable styles and configuration are established there is less need for an external diff tool, although its always useful to have a quick way to check what format tools are doing.</p> BinaryPracticalli Clojure CLI ConfigNode.js <p>Download zprint for Linux or MacOSX using the latest binary released on the GitHub repository</p> <p>Move the binary to the executable path for the operating system, updating the name to <code>zprint</code> (or use a symbolic link)</p> <p><pre><code>mv ~/Downloads/zprintl-1.2.5 ~/.local/bin/zprint\n</code></pre> Make the binary executable <pre><code>chmod a+x ~/.local/bin/zprint\n</code></pre> Ensure the zprint binary is working and examine the default configuration for zprint, including all default values and highlighting where non-default values are set <pre><code>zprint --explain-all\n</code></pre> Using zprint to check the Clojure files in the current directory and list which files require formatting <pre><code>zprint --formatted-check *.clj\n</code></pre></p> <p>A more detailed zprint report checking all the Clojure files a project, including files in the route directory and all sub-directories (i.e. <code>**/*.cjl</code> pattern) <pre><code>zprint --list-formatted-summary-check **/*.clj **/*.edn\n</code></pre> Or using short form flags <pre><code>zprint -lfsc **/*.clj **/*.edn\n</code></pre></p> <p>Update formatting for all the files in a projects, showing details of the files processed and changed <pre><code>zprint -lfsw **/*.clj *.edn *.clj\n</code></pre></p> <p>zprint can be used as a library without installing the binary.  Practicalli Clojure CLI Config defines the <code>:format/zprint</code> alias which checks the format of a file and reports which files required</p> <pre><code>clojure -M:format/zprint deps.edn\n</code></pre> <pre><code>clojure -M:format/zprint filename\n</code></pre> Clojure Alias for zprint <p>Add <code>:format/zprint</code> alias to check format and <code>:format/zprint!</code> to write format changes to a given file or filename pattern User or project deps.edn file<pre><code>:format/zprint\n{:extra-deps {zprint/zprint {:mvn/version \"1.2.4\"}}\n:main-opts  [\"-m\" \"zprint.main\"\n\"{:style :indent-only}\"\n\"--list-formatted-summary-check\"]}\n:format/zprint!\n{:extra-deps {zprint/zprint {:mvn/version \"1.2.4\"}}\n:main-opts  [\"-m\" \"zprint.main\"\n\"{:style :indent-only}\"\n\"--list-formatted-summary-write\"]}\n</code></pre> Use the alise</p> <p>zprint is available as an NPM package <pre><code>sudo --install --global zprint-clj\n</code></pre> Run zprint-clj over all Clojure files <pre><code>zprint-clj **/*.{clj,cljs,cljc,edn}\n</code></pre></p> <p>Configure zprint</p> <p>It is assumed that the majority of format needs are met by one of the following style rule sets</p> <ul> <li><code>{:style :indent-only}</code> only formats indentation, less likely to change the general style of code</li> <li><code>{:style :community}</code> a quite strict adhearence to the Clojure Community Guide (which Practicalli finds a little to strict)</li> </ul> <p>Unless the code is really messy (e.g. not written in a clojure aware editor with live linting) then <code>{:style :indent-only}</code> is a simple starting point.</p> <p>If the team have adopted most if not all community styles, then <code>{:style :community}</code> may be a more appropriate start point.  Use --explain-all flag with the zprint command to see all the rules that are applied with a partiular style and modify as appropriate</p> <p><code>$HOME/.zprintrc</code> is used for the configuration applied to all files, although this can be overridden in each project (or even as zprint comments in particular files)</p> <p>zprint - GitHub repo zprint - clojars zprint - cljdoc</p>"},{"location":"code-quality/megalinter/","title":"MegaLinter","text":"<p> MegaLinter verifies code and configuration with a a wide range of Lint and formatting tools, all from within a Docker image that minimises the install requirements.</p> <p>MegaLinter is an Open-Source tool for CI/CD workflows that analyses the consistency of your code, IAC, configuration, and scripts in your  repository sources, to ensure all your projects sources are clean and formatted whatever IDE/toolbox is used.</p> <p>The declarative MegaLinter configuration is relatively easy to learn. Typically time is spent tweaking the features (tools) of the  supported Linters</p> <p>Supported Linters have their own page listing the lint and format tools it provides, e.g.  Clojure. Each tool has its own page listing the configuration options and links to the tool homepage, e.g.  clj-kondo.</p> <p>Requirements</p> <p> Node.js is required to install and run the <code>mega-linter-runner</code> tool. Docker (Docker Desktop) is required to run MegaLinter containers locally, optionally with</p> <p>MegaLinter run via a GitHub workflow has no requirements</p>"},{"location":"code-quality/megalinter/#megalinter-locally","title":"MegaLinter Locally","text":"<p>The most effective way to manage lint and format issues is to run MegaLinter locally, before pushing changes to a Continuous Integration service.</p> <p>The MegaLinter runner uses a MegaLinter docker image will all lint tools pre-installed and configured, minimising the need to install tools locally.</p> <p>Install a recent version of  Node.js, version 18 (Long Term Support) is recommended.</p> <p><code>npx mega-linter-runner</code> runs MegaLinter without the need for a specific npm install.</p>"},{"location":"code-quality/megalinter/#create-a-configuration","title":"Create a configuration","text":"<p>Use the Practicalli MegaLinter Configuration</p> <p>Practicalli MegaLinter configuration configures tools relevant to Clojure development. Practicalli Project Templates also include Megalinter configuration and GitHub workflow.</p> <p>Create a configuration for a specific project using the MegaLinter runner command in the root of the project directory</p> <pre><code>npx mega-linter-runner\n</code></pre> <p><code>.mega-linter.yml</code> file is created at the root of the project. Review the file and ensure it has the Linters required.  MegaLinter Configuration describes the purpose of each variable.</p>"},{"location":"code-quality/megalinter/#run-megalinter","title":"Run MegaLinter","text":"<p>Use a specific flavour of MegaLinter to reduce the size of the Docker image used. A flavor is a docker image configuration for a specific programming language and its tooling.</p> <ul> <li><code>--flavor java</code> for Clojure projects</li> <li><code>--flavor documentation</code> for markdown / documentation only projects</li> </ul> <p>Other useful options include</p> <ul> <li><code>--env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\"</code> to pass a specific MegaLinter configuration file</li> <li><code>--remove-container</code> to remove the docker container once MegaLinter run has completed (the MegaLinter image will still be available)</li> </ul> <p>Run the MegaLinter runner with these options</p> <pre><code>npx mega-linter-runner --flavor java --env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\" --remove-container\n</code></pre> <p>The initial run will be slow as the MegaLinter docker image downloads and its overlays are cached.  All following runs will be significantly faster.</p> <p>make lint</p> <p><code>make lint</code> will run the MegaLinter runner using the above options, using the <code>lint</code> task from Practicalli Makefile</p>"},{"location":"code-quality/megalinter/#automatically-fix-issues","title":"Automatically fix issues","text":"<p>Use the <code>--fix</code> option with the local MegaLinter runner to automatically apply lint and format fixes that MegaLinter discovers.</p> Stage or Commit changes before MegaLinter runner automatic fix <p>If code and configuration changes are staged or committed before running with <code>--fix</code> then automatic fixes can easily be discarded or treated as a separate commit using any Git tool.</p> <pre><code>npx mega-linter-runner --fix --flavor java --env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\" --remove-container\n</code></pre>"},{"location":"code-quality/megalinter/#make-tasks","title":"Make tasks","text":"<p>Add a <code>lint</code> task to the project Makefile and run <code>make lint</code> to call the <code>mega-linter-runner</code>. Especially useful when using a different <code>--flavor</code> or using an alternative location for the configuration file, so the same approach is used each time.</p> <p>Makefile tasks for MegaLinter Runner</p> <pre><code>lint:\n$(info --------- MegaLinter Runner ---------)\nnpx mega-linter-runner --flavor java --env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\" --remove-container\n\nlint-fix:\n$(info --------- MegaLinter Runner ---------)\nnpx mega-linter-runner --fix --flavor java --env \"'MEGALINTER_CONFIG=.github/config/megalinter.yaml'\" --remove-container\n</code></pre> <p>Options for MegaLinter Runner</p> <p>MegaLinter Runner options</p>"},{"location":"code-quality/megalinter/#megalinter-configuration","title":"MegaLinter Configuration","text":"<p>Create a configuration file to use with the local <code>mega-linter-runner</code> and GitHub workflow</p> <p><code>.github/config/megalinter.yaml</code> is a recommeded location for the MegaLinter configuration file, especially when using GitHub workflow.</p> Practicalli MegaLinter Configuration <pre><code>---\n# Configuration file for MegaLinter\n#\n# General configuration:\n# https://oxsecurity.github.io/megalinter/configuration/\n#\n# Specific Linters:\n# https://oxsecurity.github.io/megalinter/latest/supported-linters/\n# ------------------------\n# Linters\n# Run linters in parallel\nPARALLEL: true\n# ENABLE specific linters, all other linters automatically disabled\nENABLE:\n- CLOJURE\n- CREDENTIALS\n- DOCKERFILE\n- MAKEFILE\n- MARKDOWN\n- GIT\n- SPELL\n- YAML\n- REPOSITORY\n# Linter specific configuration\nCLOJURE_CLJ_KONDO_CONFIG_FILE: \".github/config/clj-kondo-ci-config.edn\"\n# CLOJURE_CLJ_KONDO_ARGUMENTS: \"--lint deps.edn\"\n# CLOJURE_CLJ_KONDO_FILTER_REGEX_EXCLUDE: \"dev|develop\"\nCLOJURE_CLJ_KONDO_FILTER_REGEX_EXCLUDE: \"resources\"\n# CREDENTIALS_SECRETLINT_DISABLE_ERRORS: true\nCREDENTIALS_SECRETLINT_CONFIG_FILE: \".github/config/secretlintrc.json\"\nMARKDOWN_MARKDOWNLINT_CONFIG_FILE: \".github/config/markdown-lint.jsonc\"\nMARKDOWN_MARKDOWNLINT_FILTER_REGEX_EXCLUDE: \".github/pull_request_template.md|CHANGELOG.md\"\n# MARKDOWN_MARKDOWNLINT_DISABLE_ERRORS: false\nMARKDOWN_MARKDOWN_LINK_CHECK_CONFIG_FILE: \".github/config/markdown-link-check.json\"\n# MARKDOWN_MARKDOWN_LINK_CHECK_CLI_LINT_MODE: \"project\"\n# MARKDOWN_MARKDOWN_LINK_CHECK_DISABLE_ERRORS: false\nMARKDOWN_REMARK_LINT_DISABLE_ERRORS: true\n# MARKDOWN_MARKDOWN_TABLE_FORMATTER_DISABLE_ERRORS: false\n# SPELL_CSPELL_DISABLE_ERRORS: true\nSPELL_MISSPELL_DISABLE_ERRORS: true\n# YAML_PRETTIER_FILTER_REGEX_EXCLUDE: (docs/)\n# YAML_YAMLLINT_FILTER_REGEX_EXCLUDE: (docs/)\n# Explicitly disable linters to ensure they are never run\n# DISABLE:\n#   - COPYPASTE # checks for excessive copy-pastes\n#   - SPELL # spell checking - often creates many false positives\n#   - CSS #\n# Disable linter features\nDISABLE_LINTERS:\n- YAML_PRETTIER # draconian format rules\n- SPELL_CSPELL # many clojure references causing false positives\n- YAML_YAMLLINT # vague error mesages, investigation required\n- REPOSITORY_GIT_DIFF # warnings about LF to CRLF\n- REPOSITORY_SECRETLINT # reporting errors in its own config file\n# - REPOSITORY_DEVSKIM # unnecessary URL TLS checks\n- REPOSITORY_CHECKOV # fails on root user in Dockerfile\n- REPOSITORY_SECRETLINT\n# Ignore all errors and return without error status\n# DISABLE_ERRORS: true\n# ------------------------\n# ------------------------\n# Reporting\n# Activate sources reporter\nUPDATED_SOURCES_REPORTER: false\n# Show Linter timings in summary table at end of run\nSHOW_ELAPSED_TIME: true\n# Upload reports to file.io\nFILEIO_REPORTER: false\n# ------------------------\n# ------------------------\n# Over-ride errors\n# detect errors but do not block CI passing\n# DISABLE_ERRORS: true\n# ------------------------\n</code></pre>"},{"location":"code-quality/megalinter/#optomise-run","title":"Optomise Run","text":"<p>Run the linters in paralell to speed up the overall MegaLinter run</p> <pre><code>PARALLEL: true\n</code></pre>"},{"location":"code-quality/megalinter/#linter-groups","title":"Linter groups","text":"<p>Enable the linter groups to run. Specific linters within these groups can be enabled/disabled using Linter specific variables</p> <pre><code>ENABLE:\n- CLOJURE\n- CREDENTIALS\n- DOCKERFILE\n- MAKEFILE\n- MARKDOWN\n- GIT\n- SPELL\n- YAML\n- REPOSITORY\n</code></pre>"},{"location":"code-quality/megalinter/#linter-configuration","title":"Linter configuration","text":"<p>Configure the Clojure lint tools, which currently includes clj-kondo</p> <ul> <li><code>CLOJURE_CLJ_KONDO_CONFIG_FILE</code> to define clj-kondo configuration and lint rules to use</li> <li><code>CLOJURE_CLJ_KONDO_ARGUMENTS</code> pass arguments such as <code>--lint</code> to define a path to check rather than the whole project</li> <li><code>CLOJURE_CLJ_KONDO_FILTER_REGEX_EXCLUDE</code> to exclude one or more files or directories</li> </ul> <p>Example:</p> <pre><code>CLOJURE_CLJ_KONDO_CONFIG_FILE: \".github/config/clj-kondo-ci-config.edn\"\nCLOJURE_CLJ_KONDO_ARGUMENTS: \"--lint deps.edn\"\nCLOJURE_CLJ_KONDO_FILTER_REGEX_EXCLUDE: \"dev|develop\"\n</code></pre> <p>Explicitly disable linter tools to ensure they are never run</p> <pre><code>DISABLE_LINTERS:\n- YAML_PRETTIER # draconian format rules\n- SPELL_CSPELL # many clojure references causing false positives\n- YAML_YAMLLINT # vague error mesages, investigation required\n- REPOSITORY_GIT_DIFF # warnings about LF to CRLF\n- REPOSITORY_SECRETLINT # reporting errors in its own config file\n# - REPOSITORY_DEVSKIM # unnecessary URL TLS checks\n- REPOSITORY_CHECKOV # fails on root user in Dockerfile\n- REPOSITORY_SECRETLINT\n</code></pre> <p>Disable all errors if there are configuration issues that need troubleshooting</p> <pre><code># DISABLE_ERRORS: true\n</code></pre>"},{"location":"code-quality/megalinter/#reporting","title":"Reporting","text":"<p>Show Linter timings in summary table at end of run</p> <pre><code>SHOW_ELAPSED_TIME: true\n</code></pre> <p>Upload reports to file.io</p> <pre><code>FILEIO_REPORTER: false\n</code></pre>"},{"location":"code-quality/megalinter/#github-workflow","title":"GitHub Workflow","text":"<p> Practicalli MegaLinter GitHub Workflow</p> <p>Create a <code>.github/workflows/megalinter.yaml</code> workflow configuration, e.g  Practicalli MegaLinter Workflow</p>"},{"location":"command-line/","title":"Command Line","text":"<p>Terminal apps, shells, configuration tips, etc.</p>"},{"location":"command-line/kitty-terminal/","title":"Kitty terminal","text":"<p>Kitty Terminal is a fast, feature-rich, GPU based terminal emulator providing additional features via<code>+kitten</code> extensions.</p>"},{"location":"command-line/kitty-terminal/#install","title":"Install","text":"Ubuntu/DebianHomebrew <pre><code>sudo apt install kitty\n</code></pre> <pre><code>brew install --cask kitty\n</code></pre> <p>Copy the installed configuration to make personal changes, or start a new configuration file in <code>~/.config/kitty/kitty.conf</code></p> <pre><code>cp /usr/share/doc/kitty/examples/kitty.conf ~/.config/kitty/\n</code></pre>"},{"location":"command-line/kitty-terminal/#fonts","title":"Fonts","text":"<p>Nerd Fonts are recommended to provide icon support in Kitty</p> <p>Download a Nerd Font and configure the font in <code>kitty.conf</code></p> <p>Kitty Font and Font Family</p> <pre><code>font_family FiraCode Nerd Font\nfont_size 16\n</code></pre> <p>Or download the <code>Symbols Nerd Font</code> font package for use with any font and add the Nerd Font symbols to Kitty via a symbol map configuration.</p> Kitty Configuration for Nerd Fonts symbol map $HOME/.config/kitty/nerdfont-icons.conf<pre><code># ---------------------------------------------------------\n# NerdFont icons via symbol maps\n#\n# Kitty recommends mapping symbols rather than using patched fonts\n#\n# Download symbols only font from\n# &lt;https://github.com/ryanoasis/nerd-fonts/blob/master/src/glyphs/Symbols-2048-em%20Nerd%20Font%20Complete.ttf&gt;\n#\n# List available fonts with:\n#   kitty +list-fonts\n#\n# Troubleshoot missing/incorrect characters with:\n#   kitty --debug-font-fallback\n#\n# Reference: &lt;https://erwin.co/kitty-and-nerd-fonts/&gt;\n# Symbols Nerd Font - complete symbol_map\n# \"Nerd Fonts - Pomicons\"\nsymbol_map  U+E000-U+E00D Symbols Nerd Font\n\n# \"Nerd Fonts - Powerline\"\nsymbol_map U+e0a0-U+e0a2,U+e0b0-U+e0b3 Symbols Nerd Font\n\n# \"Nerd Fonts - Powerline Extra\"\nsymbol_map U+e0a3-U+e0a3,U+e0b4-U+e0c8,U+e0cc-U+e0d2,U+e0d4-U+e0d4 Symbols Nerd Font\n\n# \"Nerd Fonts - Symbols original\"\nsymbol_map U+e5fa-U+e62b Symbols Nerd Font\n\n# \"Nerd Fonts - Devicons\"\nsymbol_map U+e700-U+e7c5 Symbols Nerd Font\n\n# \"Nerd Fonts - Font awesome\"\nsymbol_map U+f000-U+f2e0 Symbols Nerd Font\n\n# \"Nerd Fonts - Font awesome extension\"\nsymbol_map U+e200-U+e2a9 Symbols Nerd Font\n\n# \"Nerd Fonts - Octicons\"\nsymbol_map U+f400-U+f4a8,U+2665-U+2665,U+26A1-U+26A1,U+f27c-U+f27c Symbols Nerd Font\n\n# \"Nerd Fonts - Font Linux\"\nsymbol_map U+F300-U+F313 Symbols Nerd Font\n\n#  Nerd Fonts - Font Power Symbols\"\nsymbol_map U+23fb-U+23fe,U+2b58-U+2b58 Symbols Nerd Font\n\n#  \"Nerd Fonts - Material Design Icons\"\nsymbol_map U+f500-U+fd46 Symbols Nerd Font\n\n# \"Nerd Fonts - Weather Icons\"\nsymbol_map U+e300-U+e3eb Symbols Nerd Font\n\n# Misc Code Point Fixes\nsymbol_map U+21B5,U+25B8,U+2605,U+2630,U+2632,U+2714,U+E0A3,U+E615,U+E62B Symbols Nerd Font\n# ---------------------------------------------------------\n</code></pre>"},{"location":"command-line/kitty-terminal/#multiple-sessions","title":"Multiple sessions","text":"<p>Create a new terminal session without leaving kitty by creating a new tab or a window split.</p> <p>Ctrl+Shift+T to create a new session in a tab window</p> <p>Ctrl+Shift+Left or Right to switch between tabs to the left or right</p> <p>Ctrl+Shift+Q to close a window</p> <p>Ctrl+Shift+Enter to create a new session in split window</p> <p>Ctrl+Shift+[ or ] to switch between window splits</p> <p>Ctrl+Shift+W to close a window</p> <p>Other common commands include:</p> <p>Ctrl+Shift+= to increase the font size without restarting kitty</p> <p>Ctrl+Shift+- to increase the font size without restarting kitty</p> <p>Ctrl+Shift+F11 to toggle kitty full-screen</p> <p>Ctrl+Shift+c copy from kitty terminal to clipboard</p> <p>Ctrl+Shift+v paste into to kitty terminal from clipboard</p> <p>Ctrl+Shift+s paste into to kitty terminal from clipboard Paste from Selection Ctrl+Shift+S</p>"},{"location":"command-line/kitty-terminal/#kitten-features","title":"Kitten features","text":"<p>kittens provide additional features.  Recommended features include:</p> <ul> <li>Theme kitten - in-terminal theme browser and selector</li> <li>diff - fast, side-by-side diff for the terminal with syntax highlighting</li> <li>Clipboard - Copy/paste to the clipboard from shell scripts, even over SSH</li> <li>SSH - SSH with automatic shell integration, connection re-use for low latency and easy cloning of local shell and editor configuration to the remote host</li> </ul>"},{"location":"command-line/kitty-terminal/#themes","title":"Themes","text":"<p>Theme kitten provides a simple way to browse available themes and select a theme for use</p> <p>Browse available themes and apply one, or Ctrl+c to cancel</p> <pre><code>kitty +kitten themes\n</code></pre> <p>Change themes automatically to the given theme name (the theme must exist)</p> <pre><code>kitty +kitten theme theme-name\n</code></pre> Themes used by Practicalli <p>Practicalli uses the Gruvbox Material Light Soft as the light theme <pre><code>kitty +kitten themes Gruvbox Material Light Soft\n</code></pre> Practicalli uses Gruvbox Material Dark Soft as the dark theme <pre><code>kitty +kitten themes Gruvbox Material Dark Soft\n</code></pre></p> <p>The first time the theme kitten is run the following config is added to the <code>~.config/kitty/kitty.conf</code> file and the chosen theme configuration written to the  <code>~/.config/kitty/current-theme.conf</code> file</p> <p>This configuration shows the name of the theme, which is also in the top of the <code>current-theme.conf</code> file</p> <pre><code># BEGIN_KITTY_THEME\n# GitHub Dark\ninclude current-theme.conf\n# END_KITTY_THEME\n</code></pre> <p>Icon support from Nerd fonts, download and include the configuration to show icons in terminal based editors (e.g. Neovim, Emacs, etc.)</p> <pre><code>include ./nerdfont-icons.conf\n</code></pre>"},{"location":"command-line/kitty-terminal/#diff","title":"Diff","text":"<p>The Diff kitten provides a fast way to compare files, although there is no support for merging changes.</p> <p>Kitty supports diff of image files, showing the two images side by side.</p> <pre><code>kitty +kitten diff file1 file2\n</code></pre> <p>, or &gt; jumps to next diff match</p> <p>. or &lt;  jumps to previous diff match</p> <ul> <li>All keyboard controls</li> </ul>"},{"location":"command-line/kitty-terminal/#ssh","title":"SSH","text":"<p>The <code>+kitten</code> option ensures the remote environment is configured correctly for the Kitty terminal</p> <pre><code>kitty +kitten ssh hostname\n</code></pre>"},{"location":"command-line/kitty-terminal/#example-configuration","title":"Example configuration","text":"<p>Practicalli uses the following configuration for Kitty terminal across multiple operating systems</p> ~/.config/kitty/kitty.conf<pre><code># ---------------------------------------------------------\n# Practicalli Kitty terminal theme\n#\n# Configuration using GitHub theme with light and dark options\n# using FiraCode font and NerdFont symbol mappings for icon support\n# for powerline10k and web-devicons in Neovim\n# ---------------------------------------------------------\n# ---------------------------------------------------------\n# Colorscheme / Icons\n# Icons from NerdFont (install Nerdfont symbols only theme)\ninclude ./nerdfont-icons.conf\n\n# `kitty +kitten theme` to browse available themes and apply one\n# `kitty +kitten theme theme-name` to change themes automatically\n# Favorite themese include:\n# Catppuccin-Latte and Catppuccin-Mocha\n# GitHub Light and GitHub Dark\n# BEGIN_KITTY_THEME\n# GitHub Dark\ninclude current-theme.conf\n# END_KITTY_THEME\n# ---------------------------------------------------------\n# ---------------------------------------------------------\n# Feedback\nenable_audio_bell no\n# visual_bell_color none\n# ---------------------------------------------------------\n# ---------------------------------------------------------\n# Tab styles\n# fade slant separator powerline custom hidden\ntab_bar_style powerline\ntab_bar_align left\ntab_powerline_style angled\n# ---------------------------------------------------------\n# ---------------------------------------------------------\n# Fonts\nfont_family FiraCode\n\n# Patched fonts (not recommended for Kitty)\n# font_family MesloLGS NF\n# font_family Fira Code NF\n# bold_font        auto\n# italic_font      auto\n# bold_italic_font auto\nfont_size 14\n# adjust_line_height  0\n# adjust_column_width 0\n# adjust_baseline 0\n# ---------------------------------------------------------\n</code></pre>"},{"location":"continuous-integration/","title":"Continuous integration","text":"<ul> <li>CircleCI</li> <li>GitHub Workflows and Actions</li> <li>GitLab CI</li> <li>Render.com</li> <li>fly.io</li> <li>Vercel - front-end focus</li> </ul>"},{"location":"continuous-integration/docker/","title":"Docker","text":"<p>Docker enables a consistent approach to building and running Clojure projects along with a range of other services locally (database, cache, streams, etc.), The Clojure project is built from source when starting services (a <code>watch</code> feature can rebuild on code changes). Heath checks and conditions are set to ensure dependant services start in the correct order.</p> <p>Running Docker is relatively fast once image overlays (layers) are cached on their first run, so its a viable approach for local system integration testing and acceptance testing, before pushing changes to a remote Continuous Integration service.</p> <p>A Docker workflow complements a REPL Driven Development workflow, it does not replace it.  The main development effort should still be done via a REPL connected editor, with Docker Compose focused on orchestration of services.</p>"},{"location":"continuous-integration/docker/#general-workflow","title":"General Workflow","text":"<ul> <li>Create a Clojure project, e.g. using  deps-new and Practicalli Project Templates</li> <li> Install Docker Desktop &amp;  Extensions</li> <li> Create a Dockerfile, e.g  a multi-stage build and run-time Dockerfile</li> <li> Compose services together, adding health checks and conditional starts</li> <li>REPL driven development, e.g.  Practicalli REPL Reloaded Workflow</li> <li>(optional) Automatic rebuild of Clojure project when  watching for code changes (experimental feature)</li> </ul> <p>Try the Docker getting started tutorial</p> <p>Follow the Docker Getting Started tutorial from within Docker Desktop or via the command line. <pre><code>docker run -d -p 80:80 docker/getting-started\n</code></pre></p>"},{"location":"continuous-integration/docker/#docker-desktop","title":"Docker Desktop","text":"<p>Docker desktop provides an easy way to manage Docker images, containers and volumes.  Sign in to Docker Desktop to manage your images on DockerHub.</p> <p></p> <p>There is a growing marketplace of extensions that provide very useful tools to extend the capabilities of Docker Desktop.  Search within the Docker Desktop extensions or for extensions on Docker Hub.</p> <ul> <li>Resource Usage monitor resources (cpu, memory, network, disk) used by containers and docker compose systems over time</li> <li>Disk Usage optimise use of local disk space by removing unused images, containers and volumes</li> <li>Volumes Backup &amp; Share to backup, clone, restore and share Docker volumes easily</li> <li>Logs Explorer view all container logs in one place to assist troubleshooting</li> <li>Postgres Admin PGAdmin4 open source management tool for Postgres</li> <li>Trivy scan local and remote images for security vulnerabilities</li> <li>Snyk scan local and remote images for security vulnerabilities</li> <li>Ddosify high-performance, open-source and simple load testing tool</li> </ul> <p></p>"},{"location":"continuous-integration/docker/#choosing-docker-images","title":"Choosing Docker Images","text":"<p>Docker Official Images from Docker Hub are highly recommended.  Look for the Docker Official Image tag on the image page.</p> <p></p> <ul> <li>Clojure - official Docker Image - built by the Clojure community, provides tools to build Clojure projects (Clojure CLI, Leiningen)</li> <li>Eclipse temurin OpenJDK - official Docker image - built by the community - provides the Java run-time</li> <li>Amazon Corretto is an OpenJDK distribution by Amazon AWS team, Amazon Corretto can also be installed for the local development environment</li> <li>Postgres open-source object-relational database management system</li> <li>Redis open-source, networked, in-memory, key-value data store with optional durability</li> <li>nginx open source reverse proxy &amp; load balancing for HTTP, HTTPS, SMTP, POP3 &amp; IMAP protocols, HTTP cache and a web server</li> <li>mariadb open source relational database by the original developers of MySQL and is much more efficient</li> </ul> Docker Official Image meaning <p>An Official Docker Image means the configuration of that image follows the Docker recommended practices, is well documented and designed for common use cases.</p> <p>There is no implication as to the correctness of tools, languages or service that image provides, only in the means in which they are provided.</p> <p>However, if time was invested in creating an image good enough to pass the Docker review, then it has a higher probability of being a useful image that others that are not official.</p>"},{"location":"continuous-integration/docker/#dockerfile-design","title":"Dockerfile Design","text":"<p> Dockerfile design in detail</p> <p>A multi-stage <code>Dockerfile</code> contains builder stage and an unnamed stage used as the run-time.  Optionally, the configuration can use a base image which both build and run-time stages extend.</p> <p>The builder stage caches dependencies to optimise building Clojure and the run-time stage optimises running the service efficiently and securely.</p> <p>The uberjar created by the builder image is copied over to the run-time image to keep that image as clean and small as possible (to minimise resource use).</p> <p></p> <ul> <li>Multi-stage <code>Dockerfile</code> for Clojure projects</li> <li>Docker Multi-stage builds docs</li> </ul> <p>Docker init - beta feature</p> <p><code>docker init</code> is a new (beta) feature to create <code>Dockerfile</code>, <code>.dockerignore</code> and<code>compose.yaml</code> files using Docker recommended practices.</p>"},{"location":"continuous-integration/docker/#compose-services","title":"Compose services","text":"<p>Define a <code>compose.yaml</code> file that builds the Clojure project and run services that the Clojure service requires or talks too (database, cache, mock API, etc.).</p> <p>Each service can define a heart beat which can be used as a conditional startup for other services.</p> compose.yaml new Compose configuration file <p><code>compose.yaml</code> is the new configuration file for orchestrating services locally, a simplified and extended version of <code>docker-compose.yaml</code>.</p> <p>Include the <code>build:</code> option for the Clojure service with the path to the multi-stage Dockerfile for the project (typically in the same root directory of the project, although a remote Git repository can also be used)</p> <p>The Clojure service defines a dependency on a Postgres Database.  The dependency has a condition so the Clojure service is only started once the Postgres service is healthy</p> <p>Clojure Service with Postgres Database</p> <pre><code>services:\nclojure-service:\nplatform: linux/amd64\nbuild: ./\nports: # host:container\n- 8080:8080\ndepends_on:\npostgres-database:\ncondition: service_healthy\npostgres-database:\nimage: postgres:15.2-alpine\nenvironment:\nPOSTGRES_PASSWORD: \"$DOCKER_POSTGRES_ROOT_PASSWORD\"\nhealthcheck:\ntest: [ \"CMD\", \"pg_isready\" ]\ntimeout: 45s\ninterval: 10s\nretries: 10\nports:\n- 5432:5432\n</code></pre> <p>Run the services using docker from the root of the project</p> <pre><code>docker compose up --build\n</code></pre>"},{"location":"continuous-integration/docker/#file-watcher","title":"File watcher","text":"<p>Docker provides <code>watch</code> as an experimental feature which can rebuild the Clojure service when a file change is detected.  This seems most useful when troubleshooting issues that occur during system integration testing.</p> <p>Add an <code>x-develop</code> configuration with watch under the Clojure service configuration</p> <p>Automated rebuild on file change</p> <pre><code>    x-develop:\nwatch:\n- path: ./deps.edn\naction: rebuild\n- path: ./src\naction: rebuild\n</code></pre> <p>Start the services and the file watch mode</p> <pre><code>docker compose up --detach &amp;&amp; docker compose alpha watch\n</code></pre> <p>Save changes to files and a new image for the Clojure service will be built and deployed when ready.</p>"},{"location":"continuous-integration/docker/#summary","title":"Summary","text":"<p>Docker desktop provides lots of tools to support local system integration work before code is sent to a continuous integration service (or as a temporary alternative if that CI service id down)</p> <p>Practicalli Project Templates include <code>Dockerfile</code>, <code>.dockerignore</code> and <code>compose.yaml</code> configurations for Clojure development, kick-starting the use of Docker.</p> <p>Docker images are a relatively clean way of trying out different services or even different operating systems, e.g.Ubuntu or ArchLinux.  Deleting the images removes the whole service without affecting the underlying operating system.</p> <p>MegaLinter is an excellent example of a docker image that provides a large number of tools that would otherwise need to be installed directly on the operating system.</p> <ul> <li>Docker Desktop Overview</li> <li>Docker Desktop Extensions overview</li> <li>Docker Build overview</li> <li>Docker Compose Overview ocker images are a relatively clean way of trying out different services or even different operating systems, e.g.Ubuntu or ArchLinux</li> </ul>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/","title":"Docker Multi-Stage Dockerfile for Clojure","text":"<p>Building a Clojure project from source to create a docker image provides an effective workflow for local testing and system integration.</p> <p>A multi-stage Dockerfile is recommended to ensure build tools and artefacts are not included in the final Docker image, helping minimise the size and resources used by that image.</p> Practicalli Project Templates provide Multi-stage Dockerfile <p> Practialli Project Templates provides <code>Dockerfile</code>, <code>.dockerignore</code> and <code>compose.yaml</code> configurations to optimise the build and run of Clojure projects. <pre><code>clojure -T:project/create :template practicalli/service :name practicalli/gameboard\n</code></pre> Practicalli Project Templates are included in the  Practicalli Clojure CLI Config which provides aliases for running community tools to support a wide range of development tasks.</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#builder-stage","title":"Builder stage","text":"<p>Practicalli uses the latest Clojure CLI release and the latest Long Term Support (LTS) version of  Eclipse Temurin (OpenJDK).</p> <p> Alpine Linux image variants are used to keep the image file size as small as possible, reducing local resource requirements (and image download time).</p> <p>Set builder stage image</p> <pre><code>FROM clojure:temurin-17-alpine AS builder\n</code></pre> <p><code>CLOJURE_VERSION</code> will over-ride the version of Clojure CLI in the Clojure image (which defaults to latest Clojure CLI release). Or choose an image that has a specific Clojure CLI version, e.g. <code>temurin-17-tools-deps-1.11.1.1182-alpine</code></p> <p>Set builder stage image with specific Clojure version</p> <pre><code>FROM clojure:temurin-17-alpine AS builder\nENV CLOJURE_VERSION=1.11.1.1182\n</code></pre> <p>Create directory for building the project code and set it as the working directory within the Docker container to give RUN commands a path to execute from.</p> <p>Create working directory for build</p> <pre><code>RUN mkdir -p /build\nWORKDIR /build\n</code></pre>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#cache-dependencies","title":"Cache Dependencies","text":"<p>Clojure CLI is used to download dependencies for the project and any other tooling used during the build stage, e.g. test runners, packaging tools to create an uberjar.  Dependency download should only occur once, unless the <code>deps.edn</code> file changes.</p> MakefileClojure CLIBabashka Task Runner <p>Copy the <code>deps.edn</code> file to the build stage and use the <code>clojure -P</code> prepare (dry run) command to download the dependencies without running any Clojure code or tools.</p> <p>Create dependency cache overlay</p> <pre><code>COPY deps.edn Makefile /build/\nRUN make deps\n</code></pre> <p>The dependencies are cached in the Docker overlay (layer) and this cache will be used on successive docker builds unless the <code>deps.edn</code> file or <code>Makefile</code> is change.</p> <p>Copy the <code>deps.edn</code> file to the build stage and use the <code>clojure -P</code> prepare (dry run) command to download the dependencies without running any Clojure code or tools.</p> <p>Create dependency cache overlay</p> <pre><code>COPY deps.edn /build/\nRUN clojure -P -X:build\n</code></pre> <p>The dependencies are cached in the Docker overlay (layer) and this cache will be used on successive docker builds unless the <code>deps.edn</code> file is change.</p> <p>Pull request welcome </p> <p><code>deps.edn</code> in this example contains the project dependencies and <code>:build</code> alias used build the Uberjar.</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#build-uberjar","title":"Build Uberjar","text":"<p>Copy all the project files to the docker builder working directory, creating another overlay.</p> <p>Copying the src and other files in a separate overlay to the <code>deps.edn</code> file ensures that changes to the Clojure code or configuration files does not trigger downloading of the dependencies again.</p> MakefileClojure CLIBabashka Task Runner <p>Run the <code>dist</code> task to generate an Uberjar for distribution.</p> <pre><code>COPY ./ /build\nRUN make dist\n</code></pre> <p>Run the <code>tools.build</code> command to generate an Uberjar.</p> <p><pre><code>COPY ./ /build\nRUN clojure -T:build uberjar\n</code></pre> <code>:build</code> is an alias to include Clojure tools.build dependencies which is used to build the Clojure project into an Uberjar.</p> <p>Pull request welcome</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#docker-ignore-patterns","title":"Docker Ignore patterns","text":"<p><code>.dockerignore</code> file in the root of the project defines file and directory patterns that Docker will ignore with the COPY command.  Use <code>.dockerignore</code> to avoid copying files that are not required for the build</p> <p>Keep the <code>.dockerignore</code> file simple by excluding all files with <code>*</code> pattern and then use the <code>!</code> character to explicitly add files and directories that should be copied</p> MakefileClojure CLIBabashka Task Runner <p>Docker ignore - only include specific patterns</p> <pre><code># Ignore all files\n*\n\n# Include Clojure code and config\n!deps.edn\n!Makefile\n!src/\n!test/\n!test-data/\n!resources/\n</code></pre> <p>Docker ignore - only include specific patterns</p> <pre><code># Ignore all files\n*\n\n# Include Clojure code and config\n!deps.edn\n!src/\n!test/\n!test-data/\n!resources/\n</code></pre> <p>Pull request welcome</p> <p><code>test-data</code> directory is commonly used by Practicalli to include scripts and data for testing the system once running.</p> <p>The classic approach for Docker ignoer patters is to specify all files and directories to exclude in a Clojure project, although this can lead to more maintenance as the project grows.</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#run-time-stage","title":"Run-time stage","text":"<p>The Alpine Linux version of the Eclipse Temurin image is used as it is around 5Mb in size, compared to 60Mb or more of other operating system images.</p> <p>Image for run-time stage</p> <pre><code>FROM eclipse-temurin:17-alpine AS final\n</code></pre> <p>Run-time containers are often cached in a repository, e.g. AWS Container Repository (ECR).  <code>LABEL</code> adds metadata to the container helping it to be identified in a repository or in a local development environment.</p> <pre><code>LABEL org.opencontainers.image.authors=\"nospam+dockerfile@practicall.li\"\nLABEL io.github.practicalli.service=\"Gameboard API Service\"\nLABEL io.github.practicalli.team=\"Practicalli Engineering Team\"\nLABEL version=\"1.0\"\nLABEL description=\"Gameboard API service\"\n</code></pre> <p>Use <code>docker inspect</code> to view the metadata</p> <p>Optionally, add packages to support running the service or helping to debug issue in the container when it is running.  For example, add <code>dumb-init</code> to manage processes, <code>curl</code> and <code>jq</code> binaries for manual running of system integration testing scripts for API testing.</p> <p><code>apk</code> is the package tool for Alpine Linux and <code>--no-cache</code> option ensures the install file is not part of the resulting image, saving resources.  Alpine Linux recommends setting versions to use any point release with the <code>~=</code> approximately equal version, so any same major.minor version of the package can be used.</p> <p>Add Alpine packages</p> <pre><code>RUN apk add --no-cache \\\ndumb-init~=1.2.5 \\\ncurl~=8.0.1 \\\njq~=1.6\n</code></pre> <p>Check Alpine packages if new major versions are no longer available (low frequency)</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#non-root-group-and-user","title":"Non-root group and user","text":"<p>Docker runs as root user by default and if a container is compromised the root permissions and could lead to a compromised host system. Docker recommends creating a user and group in the run-time image  to run the service</p> <p>Create a non-privileged user account</p> <pre><code>ARG UID=10001\nRUN adduser \\\n--disabled-password \\\n--gecos \"\" \\\n--home \"/nonexistent\" \\\n--shell \"/sbin/nologin\" \\\n--no-create-home \\\n--uid \"${UID}\" \\\nclojure\n</code></pre> <p>Create Non-root group and user</p> <pre><code>RUN addgroup -S practicalli &amp;&amp; adduser -S practicalli -G practicalli\n</code></pre> <p>Create directory to contain service</p> <p>Create directory to contain service archive, owned by non-root user <pre><code>RUN mkdir -p /service &amp;&amp; chown -R clojure. /service\n</code></pre></p> <p>Set user</p> <p>Instruct docker that all future commands should run as the appuser user <pre><code>USER clojure\n</code></pre></p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#copy-uberjar-to-run-time-stage","title":"Copy Uberjar to run-time stage","text":"<p>Create a directory to run the service or use a known existing path that will not clash with any existing files from the image.</p> <p>Set the working directory and copy the uberjar archive file from Builder image</p> <p>Copy Uberjar from build stage</p> <pre><code>WORKDIR /service\nCOPY --from=builder --chown=clojure:clojure /build/practicalli-service.jar /service/practicalli-service.jar\n</code></pre> <p>Optionally, add system integration testing scripts to the run-time stage for testing from within the docker container.</p> <pre><code>RUN mkdir -p /service/test-scripts\nCOPY --from=builder --chown=clojure:clojure /build/test-scripts/curl--* /service/test-scripts/\n</code></pre>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#service-environment-variables","title":"Service Environment variables","text":"<p>Define values for environment variables should they be required (usually for debugging), ensuring no sensitive values are used. Environment variables are typically set by the service provisioning the containers (AWS ECS / Kubernettes) or on the local OS host during development (Docker Desktop).</p> <pre><code># optional over-rides for Integrant configuration\n# ENV HTTP_SERVER_PORT=\n# ENV MYSQL_DATABASE=\nENV SERVICE_PROFILE=prod\n</code></pre>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#java-virtual-machine-optimisation","title":"Java Virtual Machine Optimisation","text":"<p>Clojure Uberjar runs on the Java Virtual Machine which is a highly optimised environment that rarely needs adjusting, unless there are noticeable performance or resource issue use.</p> <p>Minimum and maximum heap sizes, i.e. <code>-XX:MinRAMPercentage</code> and <code>-XX:MaxRAMPercentage</code> are typically the only optimisations required.</p> <p><code>java -XshowSettings -version</code> displays VM settings (vm), Property settings (property), Locale settings (locale), Operating System Metrics (system) and the version of the JVM used.  Add the category name to show only a specific group of settings, e.g. <code>java -XshowSettings:system -version</code>.</p> <p><code>JDK_JAVA_OPTIONS</code> can be used to tailor the operation of the Java Virtual Machine, although the benefits and constraints of options should be well understood before using them (especially in production).</p> <p>Show settings on JVM startup</p> <p>Show system settings on startup, force container mode and set memory heap maximum to 85% of host memory size. <pre><code>ENV JDK_JAVA_OPTIONS \"-XshowSettings:system -XX:+UseContainerSupport -XX:MaxRAMPercentage=85\"\n</code></pre></p> Use relative heap memory settings, not fixed sizes <p>Relative heap memory settings (<code>-XX:MaxRAMPercentage</code>) should be used for containers rather than the fixed value options (<code>-Xmx</code>) as the provisioning service for the container may control and change the resources available to a container on deployment (especially a Kubernettes system).</p> <p>Options that are most relevant to running Clojure &amp; Java Virtual Machine in a container include:</p> <ul> <li><code>-XshowSettings:system</code> display (container) system resources on JVM startup</li> <li><code>-XX:InitialRAMPercentage</code> Percentage of real memory used for initial heap size</li> <li><code>-XX:MaxRAMPercentage</code> Maximum percentage of real memory used for maximum heap size</li> <li><code>-XX:MinRAMPercentage</code> Minimum percentage of real memory used for maximum heap size on systems with small physical memory</li> <li><code>-XX:ActiveProcessorCount</code> specifies the number of CPU cores the JVM should use regardless of container detection heuristics</li> <li><code>-XX:\u00b1UseContainerSupport</code> force JVM to run in container mode, disabling container detection (only useful if JVM not detecting container environment)</li> <li><code>-XX:+UseZGC</code> low latency Z Garbage collector (read the Z Garbage collector documentation and understand the trade-offs before use) - the default Hotspot garbage collector is the most effective choice for most services</li> </ul> Only optimise if performance test data shows issues <p>Without performance testing of a specific Clojure service and analysis of the results, let the JVM use its own heuristics to determine the most optimum strategies it should use</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#expose-clojure-service","title":"Expose Clojure service","text":"<p>If Clojure service listens to network requests when running, then the port it is listening on should be exposed so the world outside the container can communicate to the Clojure service.</p> <p>e.g. expose port of HTTP Server that runs the Clojure service</p> <p>Expose service port</p> <pre><code>EXPOSE 8080\n</code></pre>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#entrypoint","title":"Entrypoint","text":"<p>Finally define how to run the Clojure service in the container.  The <code>java</code> command is used with the <code>-jar</code> option to run the Clojure service from the Uberjar archive.</p> <p>The <code>java</code> command will use arguments defined in <code>JDK_JAVA_OPTIONS</code>.</p> <p>ENTRYPOINT directive defines the command to run the service</p> <pre><code>ENTRYPOINT [\"java\", \"-jar\", \"/service/practicalli-service.jar\"]\n</code></pre> Docker ENTRYPOINT directive <p><code>ENTRYPOINT</code> is the recommended way to run a service in Docker.  <code>CMD</code> can be used to pass additional arguments to the <code>ENTRYPOINT</code> command, or used instead of <code>ENTRYPOINT</code>.</p> <p><code>jshell</code>is the default <code>ENTRYPOINT</code> for the Eclipse Temurin image. <code>jshell</code> will run if a <code>CMD</code> directive is not included in the run-time stage of the <code>Dockerfile</code>.</p> <p>The <code>ENTRYPOINT</code> command runs as process id 1 (PID 1) inside the docker container.  In a Linux system PID 1 should respond to all TERM and SIGTERM signals.</p> <p>dump-init provides a simple process supervisor and init system, designed to run as PID 1 and manage all signals and child processes effectively.</p> <p>Use <code>dumb-init</code> as the <code>ENTRYPOINT</code> command and <code>CMD</code> to pass the java command to start the Clojure service as an argument.  <code>dumb-init</code> ensures <code>TERM</code> signals are sent to the Java process and all child processes are cleaned up on shutdown.</p> <p>ENTRYPOINT to cleanly manage service</p> <pre><code>ENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\nCMD [\"java\", \"-jar\", \"/service/practicalli-service.jar\"]\n</code></pre> <p>Alternatively, run dumb-jump and java within the <code>ENTRYPOINT</code> directive, <code>ENTRYPOINT [\"/usr/bin/dumb-init\", \"--\", \"java\", \"-jar\", \"/service/practicalli-service.jar\"]</code>.  This approach cannot be overridden correctly with an additional CMD directive on the command line when using <code>docker run</code>.</p>"},{"location":"continuous-integration/docker/clojure-multi-stage-dockerfile/#build-and-run-with-docker","title":"Build and Run with docker","text":"<p>Ensure docker services are running, i.e. start docker desktop.</p> <p>Build the service and create an image to run the Clojure service in a container with <code>docker build</code>.  Use a <code>--tag</code> to help identify the image and specify the context (in this example the root directory of the current project, <code>.</code>)</p> <pre><code>docker build --tag practicalli/service-name:1.1 .\n</code></pre> <p>After the first time building the docker image, any parts of the build that havent changed will use their respective cached layers in the builder stage.  This can lead to very fast, even zero time builds.</p> <p></p> <p>Maximise use of Docker cache</p> <p>Maximising the docker cache by careful consideration of command order and design in a <code>Dockerfile</code> can have a significant positive affect on build speed.</p> <p>Each command is an overlay (layer) in the Docker image and if its respective files have not changed, then the cached version of the command will be used.</p> <p>Run the built image in a docker container using <code>docker run</code>, publishing the port number so it can be used from the host (developer environment or deployed environment).  Use the name of the image created by the tag in the docker build command.</p> <pre><code>docker run --publish 8080:8080 practicalli/service-name\n</code></pre> <p>Orchestrate multiple services with Compose</p> <p>Create a <code>compose.yml</code> file to defines all services to run to support local integration testing, optionally adding health checks and conditional starts.</p> <p>Run <code>docker compose up</code> to start all the services.</p>"},{"location":"continuous-integration/docker/compose/","title":"Compose","text":"<p>Docker Compose provides a declarative configuration for orchestrating services locally, providing a simple way to spin up services to try them out or orchestrate a whole system from numerous dependent services.</p> <p>Compose can build images for Clojure projects and conditionally run based on the health check of other supporting services, e.g. Postgres Database.</p> <p>Each service can define a heart beat which can be used as a conditional startup for other services which depend upon them.</p>"},{"location":"continuous-integration/docker/compose/#compose-configuration","title":"Compose Configuration","text":"<p><code>compose.yaml</code> is the configuration file for Docker Compose</p> <p><code>docker compose</code> command will start all services defined in the <code>compose.yaml</code> configuration (or <code>--file filename</code> to specify an alternative configuration file).</p> <pre><code>docker compose up\n</code></pre> <ul> <li><code>--build</code> option will run the build process for services that contain a <code>build:</code> configuration</li> <li><code>--detach</code> runs services in the background, compose startup logs are still shown in the foreground</li> </ul> <p>Shutdown the services with <code>down</code> (specifying <code>--file filename</code> if used in the compose up command)</p> <pre><code>docker compose down\n</code></pre> Compose simplified after Docker integration <p><code>compose.yaml</code> is the new Compose configuration file for orchestrating services locally, a simplified and extended version of <code>docker-compose.yaml</code>.  The main benefit is that a version number is no longer required, as the Compose version shipped with Docker is used.</p> <p><code>docker compose</code> the new command, replacing <code>docker-compose</code>, although the options and arguments to this command are the same for now.</p>"},{"location":"continuous-integration/docker/compose/#build-clojure-service","title":"Build Clojure Service","text":"<p>The simplest approach to building a service is to include a <code>build:</code> configuration specifying the location of a multi-stage <code>Dockerfile</code>, which has a <code>builder</code> stage to create an uberjar that is run in the run-time image.</p> <p>The <code>build:</code> option for the Clojure service with the path to the multi-stage Dockerfile for the project (typically in the same root directory of the project, although a remote Git repository can also be used)</p> <p>Clojure project build configuration</p> <pre><code># --- Docker Compose Configuration --- #\n# - Docker Compose V2\n# - https://docs.docker.com/compose/compose-file/\n#\n# Build the Clojure Service from source code\n# and run on port 8080\nname: \"practicalli\"\nservices:\n# --- Clojure Service --- #\ngameboard-service:\nplatform: linux/amd64\n# Build using Dockerfile - relative path or Git repository\nbuild:\ncontext: ./ # Use Dockerfile in project root\nenvironment:\n- COMPOSE_PROJECT_NAME\nports: # host:container\n- 8080:8080\n</code></pre> <ul> <li><code>name:</code> (optional) is used to set the container prefix of the service name, via the <code>environment:</code> variable <code>COMPOSE_PROJECT_NAME</code>, helping to identify the container by name when running.  The above container would be <code>practicalli-gameboard-service</code>.  This option is more valuable as the number of services grows</li> <li><code>services:</code> contains one or more service definitions with a unique name, e.g. <code>gameboard-service</code></li> <li><code>gameboard-service:</code> is a unique name for a service configuration</li> <li><code>platform:</code> defines the operating system and hardware architecture that should be used for the service</li> <li><code>build: context:</code> defines the location of the <code>Dockerfile</code> to use, either a local file or a Git repository URL</li> <li><code>ports:</code> defines the host:container mapping for the service port.  <code>8080:8000</code> value would map the service running within the container on <code>8000</code> to the host (e.g. engineers' computer) on port 8080.</li> </ul> <p></p> <p>Use a multi-stage <code>Dockerfile</code> to provide greater opportunity to create image overlays for the build stage which can be cached, e.g. downloading project dependencies, speeding up the build process on consecutive runs.</p>"},{"location":"continuous-integration/docker/compose/#compose-services","title":"Compose services","text":"<p>Add more unique service configurations under <code>services:</code>, e.g. <code>postgres-database</code>.  All the services that support the local testing and integration of the Clojure project can be added to the <code>compose.yaml</code> file (database, cache, mock APIs, coupled services, etc.).</p> <p>The Clojure service defines a dependency on a Postgres Database.  The dependency has a condition so the Clojure service is only started once the Postgres service is healthy</p> <p>Compose Clojure project build with Postgres database</p> <pre><code>services:\nclojure-service:\nplatform: linux/amd64\nbuild: ./\nports: # host:container\n- 8080:8080\ndepends_on:\npostgres-database:\ncondition: service_healthy\npostgres-database:\nimage: postgres:15.2-alpine\nenvironment:\nPOSTGRES_PASSWORD: \"$DOCKER_POSTGRES_ROOT_PASSWORD\"\nhealthcheck:\ntest: [ \"CMD\", \"pg_isready\" ]\ntimeout: 45s\ninterval: 10s\nretries: 10\nports:\n- 5432:5432\n</code></pre> <ul> <li><code>depends_on:</code> include one or more services that the service depends on, optionally adding a start <code>condition:</code></li> <li><code>depends_on: &lt;service-name&gt; condition:</code> a condition that should be true in order for the service image to start, typically checking <code>service_healthy</code> of another service in the configuration</li> <li><code>heathcheck:</code> define a command and options to determine if the specific service running is healthy, with the <code>test:</code> command specific to the type of service.</li> </ul> <p>Build and run the services using the <code>--build</code> flag with <code>docker compose</code></p> <pre><code>docker compose up --build\n</code></pre> <p>The Clojure project is built in parallel with running the Postgres database.</p> <p>On the initial run the Clojure project may take longer to run that starting the Postgres database, in which case the Clojure uberjar will run straight away.</p> <p>On consecutive runs, at least part of the Clojure build process should be cached and images for all the services will have been downloaded and cached.  The Clojure uberjar may wait for the Postgres database to start up.</p> <p>Each service can define a health check that can be used as a conditional startup trigger and ensure all services start in a meaningful order.</p> <p></p>"},{"location":"continuous-integration/docker/compose/#build-on-change","title":"Build on Change","text":"<p>Docker provides <code>watch</code> as an experimental feature which can rebuild the Clojure service when a file change is detected.</p> <p>The watch approach seems most useful for Clojure projects when troubleshooting issues that occur during system integration testing.</p> <p>When additional tools need to run outside of Clojure code, e.g. SaSS build, data loading / ETL, then <code>watch</code> can compliment the Clojure REPL workflow by providing incremental change management for non-clojur aspects of the project.</p> <p>Add an <code>x-develop</code> configuration with <code>watch</code> under the Clojure service configuration.  Define the action for each path to create a simple but comprehensive way to update the service</p> <p>Clojure Project - Build on Change</p> <pre><code>services:\nclojure-service:\nplatform: linux/amd64\nbuild: ./\nports: # host:container\n- 8080:8080\ndepends_on:\npostgres-database:\ncondition: service_healthy\nx-develop:\nwatch:\n- path: ./deps.edn\naction: rebuild\n- path: ./src\naction: rebuild\n</code></pre> <p>Start the services and the file watch mode</p> <pre><code>docker compose up --detach &amp;&amp; docker compose alpha watch\n</code></pre> <p>Save changes to files and a new image for the Clojure service will be built and deployed when ready.</p> <p>Optimise Docker Cache in Build process</p> <p>Using build on change approach can run quite frequently, so an optimised build process in the <code>Dockerfile</code> or <code>compose.yaml</code> configuration is especially important to make build on change fast and therefore effective to use.</p>"},{"location":"continuous-integration/docker/desktop-extensions/","title":"Docker Desktop Extensions","text":"<p>Docker Marketplace contains many useful and freely available extensions to manage the docker environment and services running within containers.</p>"},{"location":"continuous-integration/docker/desktop-extensions/#resource-usage","title":"Resource Usage","text":"<p> Resource usage</p>"},{"location":"continuous-integration/docker/desktop-extensions/#disk-usage","title":"Disk Usage","text":"<p> Disk usage</p>"},{"location":"continuous-integration/docker/desktop-extensions/#logs-explorer","title":"Logs Explorer","text":"<p> Logs Explorer</p>"},{"location":"continuous-integration/docker/desktop-extensions/#volumes-backup","title":"Volumes Backup","text":"<p> Volumes backup &amp; Share</p>"},{"location":"continuous-integration/docker/desktop-extensions/#snyk-security-scanner","title":"Snyk security scanner","text":"<p> Snyk security vulnerability scanner</p>"},{"location":"continuous-integration/docker/desktop-extensions/#postgres-admin","title":"Postgres Admin","text":"<p> PostgreSQL database monitoring</p> <p>Embedded PGAdmin4 tool for managing database schema, data and accounts</p>"},{"location":"continuous-integration/docker/desktop/","title":"Docker Desktop","text":"<p>Docker Extensions used by Practicalli</p> <p>Docker desktop provides an easy way to manage Docker images, containers and volumes.  Sign in to Docker Desktop to manage your images on DockerHub.</p> <p></p>"},{"location":"continuous-integration/docker/desktop/#learning-center","title":"Learning Center","text":"<p>Resources for learning how to use Docker effectively</p>"},{"location":"continuous-integration/docker/desktop/#images","title":"Images","text":""},{"location":"continuous-integration/docker/desktop/#containers","title":"Containers","text":"<ul> <li>container status</li> <li>view details</li> <li>logs</li> <li>inspect - environment, port values</li> <li>terminal shell within the container</li> <li>files - file browser for the container (check for uberjar, test-data, etc)</li> <li> <p>stats- basic resource usage  (Resource usage extension provides view over all containers)</p> </li> <li> <p>start / stop containers</p> </li> </ul>"},{"location":"continuous-integration/docker/desktop/#volumes","title":"Volumes","text":""},{"location":"continuous-integration/docker/desktop/#dev-environments","title":"Dev Environments","text":""},{"location":"continuous-integration/docker/dockerfile/","title":"Dockerfile","text":"<p>A Dockerfile is a declarative configuration that defines how an image is assembled and can use another image to provide much of the configuration, minimising the amount of design and maintenance required.</p> <p>Each line in the <code>Dockerfile</code> configuration creates an overlay, a layer of the image that is applied to create the final image.  Overlays are cached by docker on the first run and if the files or commands the overlays are created from do not change, then the cache is used on consecutive use of the docker image.</p> <p>A Multi-stage <code>Dockerfile</code> is an effective way to build and run projects via a continuous integration pipeline and local development (in concert with supporting services via a <code>compose.yaml</code> configuration).</p> <p>Docker Hub provides a wide range of images, supporting development, continuous integration and system integration testing.</p>"},{"location":"continuous-integration/docker/dockerfile/#multi-stage-dockerfile","title":"Multi-stage Dockerfile","text":"<p>A multi-stage <code>Dockerfile</code> contains builder stage and an unnamed stage used as the run-time.  The builder stage can be designed optimally for building the Clojure project and the run-time stage optimised for running the service efficiently and securely.</p> <p>The uberjar created by the builder image is copied over to the run-time image to keep that image as clean and small as possible (to minimise resource use).</p> Practicalli Multi-stage Dockerfile for Clojure <p> Practicalli Multi-stage <code>Dockerfile</code> for Clojure projects derived from the configuration currently used for commercial and open source work.</p> <p>The Dockerfile uses make targets, which are Clojure commands defined in the Practicalli Makefile</p>"},{"location":"continuous-integration/docker/dockerfile/#official-docker-images","title":"Official Docker images","text":"<p>Docker Hub contains a large variety of images, using those tagged with Docker Official Image is recommended.</p> <ul> <li>Clojure - official Docker Image - provides tools to build Clojure projects (Clojure CLI, Leiningen, Boot)</li> <li>Eclipse temurin OpenJDK - official Docker image - built by the community - provides the Java run-time</li> </ul> <p>Ideally a base image should be used where both builder and run-time images share the same ancestor, this helps maintain consistency between build and run-time environments.</p> <p>The Eclipse OpenJDK image is used by the Clojure docker image, so they implicitly use the same base image without needed to be specified in the project <code>Dockerfile</code>.  The Eclipse OpenJDK image could be used as a base image in the <code>Dockerfile</code> but it would mean repeating (and maintaining) much the work done by the official Clojure image)</p> <p>Alternative Docker images</p> <ul> <li>CircleCI Convenience Images =&gt; Clojure - an optimised Clojure image for use with the CircleCI service</li> <li>Amazon Corretto is an alternative version of OpenJDK</li> </ul> <p>An Official Docker Image means the configuration of that image follows the Docker recommended practices, is well documented and designed for common use cases.  There is no implication at to the correctness of tools, languages or service that image provides, only in the means in which they are provided.</p>"},{"location":"continuous-integration/docker/dockerfile/#docker-init","title":"Docker init","text":"<p><code>docker init</code> provides a command line wizard to create set of Docker configurations that follow the recommended practices</p> <pre><code>docker init\n</code></pre> <p>Specific configurations are provides for Go and Python, other languages should use the General Purpose option.</p> <p>The General purpose option provides almost all the configuration required.  Update the RUN command in the build stage to that of the specific language, ideally copying the project dependency file to the build stage and inititing a dry run to download the dependency files to create a Docker overlay cache of dependencies.</p>"},{"location":"continuous-integration/docker/dockerfile/#dockerfile-syntax","title":"Dockerfile Syntax","text":"<p>The form of <code>Dockerfile</code> instructions</p> <pre><code># Comment\nINSTRUCTION arguments\n</code></pre> <p><code>#</code> at the start of a line defines a line comment.  <code>#</code> within a line is considered an argument to the instruction.</p> <p><code>\\</code> is a line continuation character, allowing a cleaner format when using longer commands as instruction arguments.</p> <pre><code>HEALTHCHECK \\\nCMD [\"curl\", \"--fail\", \"http://localhost:8080/system-admin/status\"]\n</code></pre> <p>Start by learning the common instructions used in <code>Dockerfile</code> configurations and consult  Docker Docs extensive Dockerfile reference to understand additional instructions are required</p> <p> Docker Docs Dockerfile reference</p>"},{"location":"continuous-integration/docker/dockerfile/#from","title":"FROM","text":"<p><code>FROM</code> instruction should be the first instruction in the <code>Dockerfile</code> and specifies the image from which the current configuration uses as a base.</p> <p>FROM can be preceded ARG instructions to declare arguments used in the <code>FROM</code> instruction.  Comments <code>#</code> and parser directives can also appear before <code>FROM</code></p>"},{"location":"continuous-integration/docker/dockerfile/#copy","title":"COPY","text":"<p>Copy files from the local directory or from a URL to the Docker images.</p> <p>COPY replaces ADD</p> <p>Avoid the use of <code>ADD</code> and use <code>COPY</code> instead</p>"},{"location":"continuous-integration/docker/dockerfile/#workdir","title":"WORKDIR","text":"<p>Set the directory in the Docker image in which all future commands will run.</p> <p>Setting <code>WORKDIR</code> can simplify <code>COPY</code> and <code>RUN</code> commands</p>"},{"location":"continuous-integration/docker/dockerfile/#user","title":"USER","text":"<p>set user account to run all further commands</p>"},{"location":"continuous-integration/docker/dockerfile/#run","title":"RUN","text":"<p>execute any command recongnised within the container</p>"},{"location":"continuous-integration/docker/dockerfile/#healthcheck","title":"HEALTHCHECK","text":"<p>Docker Service heathcheck provides a simple mechanism to report that a service is running.  A health check is a vital configuration to provide for production systems to ensure failing containers are replaced by working containers automatically.</p> <p>The status of the service can be checked manually using the <code>docker inspect</code> command</p> <pre><code>docker inspect --format='{{json .State.Health}}' container-name\n</code></pre> <p>Define a <code>HEALTHCHECK CMD</code> to identify the current status of the service running within the container, e.g. a curl command to test an API endpoint that demonstrated the service is running.</p> <p>Heathcheck options include</p> <ul> <li><code>--interval</code> frequency to run the health check</li> <li><code>--timeout</code> maximum time to wait for a response to the health check command</li> <li><code>--start-period</code> grace period for the service to start up before the first health check runs</li> <li><code>--retries</code> number of times to repeat the command before reporting failure (reports .... until success or failure)</li> </ul> <p>Wait 10 seconds before running the first health check, then try every 5 seconds and wait 3 seconds for a response.  Run the health check a maximum of 2 times before reporting failure (assuming successful check has not been returned).</p> <pre><code>--interval=5s --timeout=3s --start-period=10s --retries=2\n</code></pre> <p>HEALTHCHECK using shell command</p> <pre><code>HEALTHCHECK \\\nCMD curl --fail http://localhost:8080/system-admin/status || exit 1\n</code></pre> <p>HEALTHCHECK using Docker Exec array command</p> <pre><code>HEALTHCHECK \\\nCMD [\"curl\", \"--fail\", \"http://localhost:8080/system-admin/status\"]\n</code></pre> <p>Compose can also define a health check</p> <p><code>compose.yaml</code> can include a health check for each service defined which can be used by the service being built to conditionally start.</p> <p>Add a health-check to the <code>compose.yaml</code> configuration when the service being built requires a database or similar service that should be available before starting.</p> <p>Avoid defining a health-check in the <code>compose.yaml</code> for services that already have an adequate health-check defined in ther <code>Dockerfile</code></p>"},{"location":"continuous-integration/docker/dockerfile/#entrypoint","title":"ENTRYPOINT","text":"<p>Define the default command to run once the container is started.</p> <p>The image used to create the final stage from may have a default command, e.g. Eclipse Temurin image provides the <code>jshell</code> ENTRYPOINT, which is overridden by supplying an ENTRYPOINT in the <code>Dockerfile</code> for the current project.</p> <p><code>ENTRYPOINT</code> is typically used with <code>CMD</code></p> <p>Process manager ENTRYPOINT with service CMD</p> <p>Start dumb-init to manage the CMD process that calls the java run-time. <code>dumb-init</code> ensures SIGTERM signals are sent to the <code>java</code> process ensuring a clean shutdown <pre><code>ENTRYPOINT [\"/usr/bin/dumb-init\", \"--\"]\nCMD [\"java\", \"-jar\", \"/service/practicalli-suit-you-sir-standalone.jar\"]\n</code></pre></p> <p> Docker Entrypoint documentation</p>"},{"location":"continuous-integration/docker/dockerfile/#cmd","title":"CMD","text":"<p>The command to run the service within the container, typically paired with ENTRYPOINT</p> <p>CMD can be supplied on the command line when calling docker to over-ride the CMD defined in the <code>Dockerfile</code>, e.g. to help test a Docker image that is not running correctly or run variations of the service such as debug mode.</p>"},{"location":"continuous-integration/docker/images/","title":"Docker Images","text":"<p>Docker Official Images from Docker Hub are highly recommended.  Look for the Docker Official Image tag on the image page.</p> <p></p> <ul> <li>Postgres open-source object-relational database management system</li> <li>Redis open-source, networked, in-memory, key-value data store with optional durability</li> <li>nginx open source reverse proxy &amp; load balancing for HTTP, HTTPS, SMTP, POP3 &amp; IMAP protocols, HTTP cache and a web server</li> <li>mariadb open source relational database by the original developers of MySQL and is much more efficient</li> </ul> Docker Official Image meaning <p>An Official Docker Image means the configuration of that image follows the Docker recommended practices, is well documented and designed for common use cases.</p> <p>There is no implication as to the correctness of tools, languages or service that image provides, only in the means in which they are provided.</p> <p>However, if time was invested in creating an image good enough to pass the Docker review, then it has a higher probability of being a useful image that others that are not official.</p>"},{"location":"continuous-integration/docker/images/#alpine-linux","title":"Alpine Linux","text":"<p> Alpine Linux images have a very small footprint and provide the essential tools for running services that do not depend on specific operating system packages.</p> <p>As images are very small, resources used both locally and in stage and production environments are minimal.  This can be a simple way to reduce costs and do more with far fewer resources.</p> <p>Alpine Linux uses the <code>pkg</code> tool for package management, to add tools and libraries to support a Dockerfile build stage if required.</p>"},{"location":"continuous-integration/docker/images/#openjdk","title":"OpenJDK","text":"<p>OpenJDK is the most commonly used run-time environment for Java and JVM languages (Clojure, Kotlin, Gradle, Jython, JRuby, etc.)</p> <p> Eclipse temurin OpenJDK - official Docker image is built by the  Java community and provides the Java run-time (Java Virtual Machine).  Eclipse Temurin provides all Long Term Support (LTS) versions from Java 8 onward and current intermediate releases.  Variants are available with Alpine Linux and a wide range of system architectures (<code>amd64</code>, <code>arm32v7</code>, <code>arm64v8</code>, <code>ppc64le</code>, <code>s390x</code>, <code>windows-amd64</code>)</p>"},{"location":"continuous-integration/docker/images/#amazon-corretto","title":"Amazon Corretto","text":"<p> Amazon Corretto is an OpenJDK distribution by Amazon AWS team and may be an appropriate choice if relying on Amazon support.</p> <p>Amazon Corretto can also be installed for the local development environment, providing a consistent run-time between development and production.</p>"},{"location":"continuous-integration/docker/images/#clojure","title":"Clojure","text":"<p> Clojure - official Docker Image - built by the Clojure community, provides tools to build Clojure projects (Clojure CLI, Leiningen)</p> <p>The Clojure image is built from the equivalent Eclipse Temurin image which can be used as the run-time image for a Multi-stage Dockerfile final stage.  As the build and final stages are built upon the same underlying image, a separate base stage is not required.</p> <p> Clojure - official Docker Image</p>"},{"location":"continuous-integration/docker/install/","title":"Install Docker CE and Desktop","text":"<p>Docker community edition provides the back-end services to run docker images in containers.</p> <p>Docker Desktop provides a graphical UI for managing images, containers and volumes.</p>"},{"location":"continuous-integration/docker/install/#install-docker-community-edition","title":"Install Docker Community Edition","text":"Ubuntu / Debian Install <p>Install via the package archive manage by the Docker team.  Add the Docker team public key and archive, then install the Docker community edition (CE) related packages.</p> <p>Ubuntu Prerequisites to use the Docker team keys (may already be installed).</p> <pre><code>sudo apt-get install ca-certificates curl gnupg lsb-release\n</code></pre> <p>Add the Docker team public key to Ubuntu package manager, ensuring only official Docker packages are used</p> <pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n</code></pre> <p>Add the Docker PPA to the Ubuntu package manager, creating a <code>/etc/apt/sources.list.d/docker.list</code> file.</p> <pre><code>echo \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n$(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>Install Docker community edition packages</p> <pre><code>sudo apt update &amp;&amp; sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin docker-desktop\n</code></pre>"},{"location":"continuous-integration/docker/install/#install-docker-desktop","title":"Install Docker Desktop","text":"Ubuntu / Debian Install <p> Download the DEB package for Docker Desktop UI and install using Ubuntu package manager <pre><code>sudo apt install ./Downloads/docker-desktop-4.19.0-amd64.deb\n</code></pre></p>"},{"location":"continuous-integration/docker/install/#post-install","title":"Post Install","text":"<p>Docker runs under the <code>docker</code> operating system group for greater security.  User accounts should be included in the <code>docker</code> group to run Docker community edition.</p> Ubuntu / Debian Install <p>Add the current operating system user account to the <code>docker</code> operating system group, creating the <code>docker</code> group if it doesn't already exist</p> <pre><code>sudo groupadd docker\nsudo usermod -aG docker $USER\n</code></pre> <p>A user must completely logout of the current login session before the <code>docker</code> group is applied.</p> <p><code>groups</code> lists all the operating system groups the current user is assigned to.</p>"},{"location":"continuous-integration/docker/install/#start-docker-docker-desktop","title":"Start Docker &amp; Docker Desktop","text":"<p>Starting Docker Desktop will automatically start the underlying Docker community edition that provides the run-time for docker comtainers.</p> Ubuntu / Debian Install <p>Use the Ubuntu application launcher to start Docker Desktop, or use the <code>systemctl</code> command from a terminal.</p> <pre><code>systemctl --user start docker-desktop\n</code></pre> <p>Docker desktop may automatically restart itself on first run</p>"},{"location":"continuous-integration/docker/install/#check-docker-works","title":"Check Docker works","text":"<p>Use the Docker tutorial image to check that Docker can run a container from an image (and also learn about Docker if new to the tools).</p> <pre><code>docker run -dp 80:80 docker/getting-started\n</code></pre> <p>The tutorial image will be downloaded and the image run in a container</p> <pre><code>\u276f docker run -dp 80:80 docker/getting-started\n\nUnable to find image 'docker/getting-started:latest' locally\nlatest: Pulling from docker/getting-started\nc158987b0551: Already exists\n1e35f6679fab: Pull complete\ncb9626c74200: Pull complete\nb6334b6ace34: Pull complete\nf1d1c9928c82: Pull complete\n9b6f639ec6ea: Pull complete\nee68d3549ec8: Pull complete\n33e0cbbb4673: Pull complete\n4f7e34c2de10: Pull complete\nDigest: sha256:d79336f4812b6547a53e735480dde67f8f8f7071b414fbd9297609ffb989abc1\nStatus: Downloaded newer image for docker/getting-started:latest\n215c033924260874013394d1f27fa5ec587f183ee9851d3a48884a1422fcc732\n</code></pre> <p>Open the tutorial website at http://localhost/ and follow the tutorial steps to learn more about Docker.</p> <p>Increase concurrent download of image overlays</p> <p>increase the max-concurrent-downloads value from the default 3 to 24, to download multi-layered docker images faster .docker/config.json<pre><code>{\n    \"auths\": {},\n    \"credsStore\": \"desktop\",\n    \"currentContext\": \"default\",\n    \"max-concurrent-downloads\": 24\n}\n</code></pre></p>"},{"location":"continuous-integration/docker/install/#check-installed-versions","title":"Check installed versions","text":"<p>Print the version of Docker CE installed.  If Docker Desktop is running, then version its information is also printed.</p> <pre><code>docker version\n</code></pre> <p>Example output (once Docker Desktop is running)</p> <pre><code>\u276f docker version\nClient: Docker Engine - Community\n Cloud integration: v1.0.31\n Version:           23.0.6\n API version:       1.42\n Go version:        go1.19.9\n Git commit:        ef23cbc\n Built:             Fri May  5 21:18:13 2023\nOS/Arch:           linux/amd64\n Context:           desktop-linux\n\nServer: Docker Desktop 4.19.0 (106363)\nEngine:\n  Version:          23.0.5\n  API version:      1.42 (minimum version 1.12)\nGo version:       go1.19.8\n  Git commit:       94d3ad6\n  Built:            Wed Apr 26 16:17:45 2023\nOS/Arch:          linux/amd64\n  Experimental:     false\ncontainerd:\n  Version:          1.6.20\n  GitCommit:        2806fc1057397dbaeefbea0e4e17bddfbd388f38\n runc:\n  Version:          1.1.5\n  GitCommit:        v1.1.5-0-gf19387a\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre> <p>Check compose version</p> <pre><code>docker compose version\n</code></pre> <p>Example output</p> <pre><code>\u276f docker compose version\nDocker Compose version v2.17.3\n</code></pre>"},{"location":"continuous-integration/docker/install/#optimise-log-rotation","title":"Optimise Log rotation","text":"<p>Docker uses the <code>json-file</code> driver which creates JSON objects of log events from all containers.  To avoid disk space issues, configure log rotation in a <code>/etc/docker/daemon.json</code> file</p> <pre><code>{\n\"log-driver\": \"json-file\",\n\"log-opts\": {\n\"max-size\": \"10m\",\n\"max-file\": \"3\"\n}\n}\n</code></pre> <p>Use the local file logging driver if a longer logging history is desirable.  The local file logging driver preserves 100Mb of logs per container (5 x 20Mb files) and uses automatic compression to greatly reduce disk consumption.</p> <pre><code>{\n\"log-driver\": \"local\",\n\"log-opts\": {\n\"max-size\": \"10m\"\n}\n}\n</code></pre> <p>--log-driver flag with <code>docker container create</code> or <code>docker run</code> commands sets the log driver for the specific container, over-riding the global setting</p> <ul> <li>JSON File logging driver</li> </ul>"},{"location":"continuous-integration/github/","title":"GitHub Workflows and Actions","text":"<p>A GitHub workflow defines one or more jobs to carry out as part of a continuous integration run.</p> <p>Workflows are triggered by events, usually bit Git related actions (commit, PR, etc.) or by schedule or human interaction with the GitHub website.</p> <p>GitHub Actions provide common jobs that can be used within a workflow, greatly reducing the configuration required to get tasks done.</p>"},{"location":"continuous-integration/github/actions/","title":"GitHub Actions","text":"<p>GitHub Actions are pre-defined tasks that can be used within a GitHub Workflow, triggered by events such as committing to a branch or pull request.</p> <p>GitHub Actions Marketplace  contains a wide range of actions that can be used to quickly create a workflow.</p> <p>Use major version only</p> <p>Use the major version of a GitHub action within a GitHub workflows to minimise the maintenance of action versions in workflow configuration.  e.g. if the latest version is <code>v5.2.1</code>, then use version <code>v5</code> to use the latest version available within that major version.</p>"},{"location":"continuous-integration/github/actions/#authentication","title":"Authentication","text":"<p>GitHub actions have read access to repositories, allowing them to checkout code and configuration.  For more permissions the GitHub Action requires an authorisation token.</p> <p>GitHub automatically creates a token that GitHub actions can use to make an authenticated API request, scoped to the current repository.</p> Use automatically created token<pre><code>      - uses: actions/action-name@v2\nwith:\nrepo-token: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> <p>For customised authentication or access to a different GitHub repository, create a developer token and save it as a user or organisation secret.</p> <p>GitHub - Automatic token authentication</p>"},{"location":"continuous-integration/github/actions/#common-github-actions","title":"Common GitHub Actions","text":"Action Description Checkout Checkout repository to enable workflow to access Cache cache dependencies and build outputs to improve workflow execution time Changelog Enforcer checks the CHANGELOG.md file has been updated for a pull request MegaLinter verify code and configuration consistency Setup reviewdog Setup reviewdog post review comments to pull requests, typically used with lint tools Clojure lint clj-kondo lint with reviewdog comments added inline to pull request Setup java jdk setup up Java run-time environment (specify version, distribution, etc) Setup clojure Setup Clojure environment and common Clojure tools for quality (clj-kondo, cljstyle, unit testing, etc) Setup go sets up a Go language environment Setup node setup a version of the Node.js environment, caching npm/yarn /pnpm dependencies Setup python Provides python or PyPy, optionally cache pip dependencies GitHub Pages Deploy deploy to GitHub pages, including cross-repository deployments <p>Actions to investigate</p> <ul> <li>clj-watson - software composition analysis (SCA)</li> <li>clj-homes - SAST (Static application security testing) tool</li> <li>Clojure Dependency Update Action - update project dependency versions for Clojure CLI, Shadow-cljs, Leiningen, Boot and Maven Pom.xml</li> <li>Clojure-Autodoc Action - generate HTML API documentation from a Clojure project</li> <li>Clojars Release Action</li> </ul>"},{"location":"continuous-integration/github/common-jobs/","title":"Common GitHub Workflow Jobs","text":"<p>Common job configuration snippets taken from GitHub workflows, showing options typically used with GitHub actions.</p>"},{"location":"continuous-integration/github/common-jobs/#basic-workflow-information","title":"Basic workflow information","text":"<p>Echo information regarding the triggering of the workflow, to help diagnose issues should they arise</p> <p>Git Checkout Action</p> <pre><code>jobs:\nworkflow:\nname: workflow-name\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n</code></pre> <p>Add a summary of the workflow at the end of the configuration.</p> <pre><code>      # Summary and status\n- run: echo \"\ud83c\udfa8 Workflow name completed\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre>"},{"location":"continuous-integration/github/common-jobs/#git-checkout","title":"Git Checkout","text":"<p>Check-out the project from version control, fetching the whole history with <code>fetch-depth: 0</code>. Set <code>fetch-depth:</code> to 1 (or remove the option) to checkout the single commit for the ref/SHA that triggered the workflow</p> <p>Echo the GitHub Repository that was cloned to the workflow log, to support debugging efforts.</p> <p>Git Checkout Action</p> <pre><code>      # Git Checkout\n- name: Checkout Code\nuses: actions/checkout@v3\nwith:\ntoken: \"${{ secrets.PAT || secrets.GITHUB_TOKEN }}\"\nfetch-depth: 0   # fetch all history\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n</code></pre>"},{"location":"continuous-integration/github/common-jobs/#pull-request-first-interaction","title":"Pull Request first interaction","text":"<p>first-interaction returning Bad Credentials error</p> <p>Add messages to a contributor's first issue or pull request to a repository.</p> <p>In this example, the contributing guide is added as a comment to the issue or pull request.</p> <p>First Interaction Action</p> <pre><code>      # Message on first interaction\n- name: First interaction\nuses: actions/first-interaction@v1.1.1\nwith:\n# Token for the repository\nrepo-token: \"{{ secrets.GITHUB_TOKEN }}\"\n# Comment to post on an individual's first issue\nissue-message: \"[Practicalli Contributing Guide](https://practical.li/spacemacs/introduction/contributing/)\"\n# Comment to post on an individual's first pull request\npr-message: \"[Practicalli Contributing Guide](https://practical.li/spacemacs/introduction/contributing/)\"\n</code></pre>"},{"location":"continuous-integration/github/trigger-events/","title":"Trigger Workflows","text":"<p>GitHub workflows are triggered by events.</p> <p>Events related to a GitHub workflow include</p> <ul> <li>pull request</li> <li>push</li> <li>workflow_dispatch (Manual run)</li> <li>Schedule (Cron)</li> </ul> <p>Scheduled Version Check</p> <p>Scheduled Version Check GitHub workflow uses the cron schedule to check for newer versions of Clojure libraries and GitHub actions</p>"},{"location":"continuous-integration/github/trigger-events/#cron-schedule","title":"Cron schedule","text":"<p>GitHub workflows can use <code>cron:</code> to define a schedule as to when a workflow should run.</p> <p>A POSIX Cron pattern is used to define the schedule</p> <ul> <li>Minute [0,59]</li> <li>Hour [0,23]</li> <li>Day of the month [1,31]</li> <li>Month of the year [1,12]</li> <li>Day of the week ([0,6] with 0=Sunday)</li> </ul> <pre><code>    name: \"Scheduled Version Check\"\non:\nschedule:\n- cron: \"0 4 * * *\" # at 04:04:04 ever day\n# - cron: \"0 4 * * 5\" # at 04:04:04 ever Friday\n# - cron: \"0 4 1 * *\" # at 04:04:04 on first day of month\n</code></pre> <p>Scheduled version check uses cron schedule</p> Cron references <ul> <li><code>on.schedule</code> - GitHub workflow syntax</li> <li>Cron Expression Syntax Cheatsheet</li> </ul>"},{"location":"continuous-integration/github/trigger-events/#workflow-dispatch","title":"Workflow Dispatch","text":"<p>Add <code>workflow_dispatch:</code> without arguments to the <code>on:</code> directive in a workflow configuration file to manually trigger the running of the workflow.</p> <p>Visit GitHub.com &gt; Actions &gt; Workflow Name in the repository and select <code>Run</code></p>"},{"location":"continuous-integration/github/trigger-events/#conditional-on-other-workeflow","title":"Conditional on other workeflow","text":"<p>Run a workflow based on the outcome of running another GitHub workflow</p> <p>Run workflow if MegaLinter workflow returns success</p> <pre><code>    name: \"Publish Documentation\"\non:\n# Run work flow conditional on linter workflow success\nworkflow_run:\nworkflows:\n- \"MegaLinter\"\npaths-ignore:\n- README.md\n- CHANGELOG.md\n- .gitignore\nbranches:\n- main\ntypes:\n- completed\n</code></pre>"},{"location":"continuous-integration/github/workflows/","title":"GitHub workflows","text":"<p>The marketplace page for a GitHub action should specify how it is used within a GitHub workflow.</p>"},{"location":"continuous-integration/github/workflows/#event-triggers","title":"Event Triggers","text":"<p>Workflows can be triggered by </p> <ul> <li>commit to branch</li> <li><code>pull_request</code></li> <li><code>cron</code> scheduled event</li> <li><code>workflow_dispatch</code> manual trigger</li> </ul>"},{"location":"continuous-integration/github/workflows/#include-exclude-patterns","title":"Include Exclude patterns","text":"<p>Files and directories to include or exclude within the scope of a trigger.  </p> <p>e.g. ingnore a pull request when changes are only in the <code>README.md</code> file</p> <pre><code>    name: Workflow name\non:\npull_request:\npaths-ignore:\n- \"README.md\"\n</code></pre>"},{"location":"continuous-integration/github/workflows/#github-action-version","title":"GitHub Action version","text":"<p>GitHub actions typically use semantic versioning for their releases</p> Semantic versioning <p>Given a version number MAJOR.MINOR.PATCH, increment the:</p> <ul> <li>MAJOR version for incompatible API changes</li> <li>MINOR version to add functionality in a backward compatible manner</li> <li>PATCH version for backward compatible bug fixes</li> <li>Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.</li> </ul> <p>Semantic Versioning 2.0.0 Specification </p> <p>Specify the major release the major version will use the latest version within that scope, e.g. <code>action/checkout@v3</code> will use <code>v3.5.2</code>, the latest version within that major version</p> <pre><code>steps:\n- uses: actions/checkout@v3\n</code></pre> Use major version of Action in workflow configuration <p>Use the major version of a GitHub action within a GitHub workflows to minimise maintenance of the workflow configuration.</p> <p>Use a specific patch release tag when a specific version is reqiured, providing a consistent version that is used each time.</p> <pre><code>steps:\n- uses: actions/checkout@v1.0.1\n</code></pre> <p>Use a branch name, commonly used for release management</p> <pre><code>steps:\n- uses: actions/checkout@v1-beta\n</code></pre> <p>Using a commit's SHA for release management Every Git commit has a unique and immutable SHA value, calculated in part from the contents of the commit. </p> <p>A SHA value can be more reliable than specifying a tag value which could be deleted or moved.</p> <p>Using a SHA value does means only that specific commit is used, so a new SHA value must be used if a newer version is required. The full SHA value of the commit must be used, not the abbreviated value.</p> <pre><code>steps:\n- uses: actions/checkout@172239021f7ba04fe7327647b213799853a9eb89\n</code></pre> <p> GitHub: creating actions reference</p>"},{"location":"continuous-integration/github/workflows/megalinter/","title":"MegaLinter Workflow","text":"<p>The MegaLinter Workflow uses a configuration file to define which linters should be run as well as specify linter specific configuration files.</p> <p>Practicalli MegaLinter Workflow</p> <pre><code>---\n# MegaLinter GitHub Action configuration file\n# More info at https://megalinter.github.io\n# All variables described in https://megalinter.github.io/configuration/\nname: MegaLinter\non:\nworkflow_dispatch:\npull_request:\nbranches: [main]\npush:\nbranches: [main]\n# Run Linters in parallel\n# Cancel running job if new job is triggered\nconcurrency:\ngroup: \"${{ github.ref }}-${{ github.workflow }}\"\ncancel-in-progress: true\njobs:\nmegalinter:\nname: MegaLinter\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n# Git Checkout\n- name: Checkout Code\nuses: actions/checkout@v3\nwith:\ntoken: \"${{ secrets.PAT || secrets.GITHUB_TOKEN }}\"\nfetch-depth: 0\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n# MegaLinter Configuration\n- name: MegaLinter Run\nid: ml\n## latest release of major version\nuses: oxsecurity/megalinter/flavors/java@v6\nenv:\n# ADD CUSTOM ENV VARIABLES OR DEFINE IN MEGALINTER_CONFIG file\nMEGALINTER_CONFIG: .github/config/megalinter.yaml\nGITHUB_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\" # report individual linter status\n# Validate all source when push on main, else just the git diff with live.\nVALIDATE_ALL_CODEBASE: &gt;-\n${{ github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'}}\n# Upload MegaLinter artifacts\n- name: Archive production artifacts\nif: ${{ success() }} || ${{ failure() }}\nuses: actions/upload-artifact@v3\nwith:\nname: MegaLinter reports\npath: |\nmegalinter-reports\nmega-linter.log\n# Summary and status\n- run: echo \"\ud83c\udfa8 MegaLinter quality checks completed\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre>"},{"location":"continuous-integration/github/workflows/megalinter/#apply-fixes","title":"Apply Fixes","text":"<p>The MegaLinter workflow can also apply fixes it finds to pull requests and commit_message</p> <p>Applying fixes can make for confusing commits</p> <p>Using the <code>--fix</code> option with the  local MegaLinter runner is a more effective way to manage automatic fixes by MegaLinter, especially if code and configuration changes are staged or committed before automatically fixing.  Automatic fixes can then be discarded or treated as a separate commit using any Git tool.</p> MegaLinter Workflow with Apply Fixes .github/workflow/megalinter.yaml<pre><code>---\n# MegaLinter GitHub Action configuration file\n# More info at https://megalinter.github.io\n# All variables described in https://megalinter.github.io/configuration/\nname: MegaLinter\non:\nworkflow_dispatch:\npull_request:\nbranches: [main]\npush:\nbranches: [main]\nenv:\n# Apply linter fixes configuration\nAPPLY_FIXES: all # APPLY_FIXES must be defined as environment variable\nAPPLY_FIXES_EVENT: pull_request # events that trigger fixes on a commit or PR (pull_request, push, all)\nAPPLY_FIXES_MODE: pull_request # are fixes are directly committed (commit) or posted in a PR (pull_request)\n# Run Linters in parallel\n# Cancel running job if new job is triggered\nconcurrency:\ngroup: \"${{ github.ref }}-${{ github.workflow }}\"\ncancel-in-progress: true\njobs:\nmegalinter:\nname: MegaLinter\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n# Git Checkout\n- name: Checkout Code\nuses: actions/checkout@v3\nwith:\ntoken: \"${{ secrets.PAT || secrets.GITHUB_TOKEN }}\"\nfetch-depth: 0\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n# MegaLinter Configuration\n- name: MegaLinter Run\nid: ml\n## latest release of major version\nuses: oxsecurity/megalinter/flavors/java@v6\nenv:\nMEGALINTER_CONFIG: .github/config/megalinter.yaml\nGITHUB_TOKEN: \"${{ secrets.GITHUB_TOKEN }}\" # report individual linter status\n# Validate all source when push on main, else just the git diff with live.\nVALIDATE_ALL_CODEBASE: &gt;-\n${{ github.event_name == 'push' &amp;&amp; github.ref == 'refs/heads/main'}}\n# Upload MegaLinter artifacts\n- name: Archive production artifacts\nif: ${{ success() }} || ${{ failure() }}\nuses: actions/upload-artifact@v2\nwith:\nname: MegaLinter reports\npath: |\nmegalinter-reports\nmega-linter.log\n# Create pull request if applicable (for now works only on PR from same repository, not from forks)\n- name: Create Pull Request with applied fixes\nid: cpr\nif: steps.ml.outputs.has_updated_sources == 1 &amp;&amp; (env.APPLY_FIXES_EVENT == 'all' || env.APPLY_FIXES_EVENT == github.event_name) &amp;&amp; env.APPLY_FIXES_MODE == 'pull_request' &amp;&amp; (github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository) &amp;&amp; !contains(github.event.head_commit.message, 'skip fix')\nuses: peter-evans/create-pull-request@v4\nwith:\ntoken: ${{ secrets.PAT || secrets.GITHUB_TOKEN }}\ncommit-message: \"[MegaLinter] Apply linters automatic fixes\"\ntitle: \"[MegaLinter] Apply linters automatic fixes\"\nlabels: bot\n- name: Create PR output\nif: steps.ml.outputs.has_updated_sources == 1 &amp;&amp; (env.APPLY_FIXES_EVENT == 'all' || env.APPLY_FIXES_EVENT == github.event_name) &amp;&amp; env.APPLY_FIXES_MODE == 'pull_request' &amp;&amp; (github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository) &amp;&amp; !contains(github.event.head_commit.message, 'skip fix')\nrun: |\necho \"Pull Request Number - ${{ steps.cpr.outputs.pull-request-number }}\"\necho \"Pull Request URL - ${{ steps.cpr.outputs.pull-request-url }}\"\n# Push new commit if applicable (for now works only on PR from same repository, not from forks)\n- name: Prepare commit\nif: steps.ml.outputs.has_updated_sources == 1 &amp;&amp; (env.APPLY_FIXES_EVENT == 'all' || env.APPLY_FIXES_EVENT == github.event_name) &amp;&amp; env.APPLY_FIXES_MODE == 'commit' &amp;&amp; github.ref != 'refs/heads/main' &amp;&amp; (github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository) &amp;&amp; !contains(github.event.head_commit.message, 'skip fix')\nrun: sudo chown -Rc $UID .git/\n- name: Commit and push applied linter fixes\nif: steps.ml.outputs.has_updated_sources == 1 &amp;&amp; (env.APPLY_FIXES_EVENT == 'all' || env.APPLY_FIXES_EVENT == github.event_name) &amp;&amp; env.APPLY_FIXES_MODE == 'commit' &amp;&amp; github.ref != 'refs/heads/main' &amp;&amp; (github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository) &amp;&amp; !contains(github.event.head_commit.message, 'skip fix')\nuses: stefanzweifel/git-auto-commit-action@v4\nwith:\nbranch: ${{ github.event.pull_request.head.ref || github.head_ref || github.ref }}\ncommit_message: \"[MegaLinter] Apply linters fixes\"\n# Summary and status\n- run: echo \"\ud83c\udfa8 MegaLinter quality checks completed\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre> <p>Reference: MegaLinter Configuration</p> <p>MegaLinter Installation  defines a GitHub workflow which includes creating a commit or pull request to automatically apply fixes.</p>"},{"location":"continuous-integration/github/workflows/practicalli/","title":"Workflows for Practicalli","text":"<p>Practicalli books and other content websites use the following GitHub workflows.</p>"},{"location":"continuous-integration/github/workflows/practicalli/#megalinter","title":"MegaLinter","text":"<p> Practicalli MegaLinter workflow</p>"},{"location":"continuous-integration/github/workflows/practicalli/#changelog-update-check","title":"Changelog Update Check","text":"<p>Check the CHANGELOG.md file has been updated for a pull request, providing a reminder to add a summary of changes for the pull request</p> <p>Defines <code>changelog-check-skip</code> label on a pull request instructs the workflow not to run</p> <p>Changelog Checker</p> .github/workflows/changelog-check.yml<pre><code>---\n# Check CHANGELOG.md file updated for every pull request\nname: Changelog Check\non:\npull_request:\npaths-ignore:\n- \"README.md\"\ntypes: [opened, synchronize, reopened, ready_for_review, labeled, unlabeled]\njobs:\nchangelog:\nname: Changelog Update Check\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n# Git Checkout\n- name: Checkout Code\nuses: actions/checkout@v3\nwith:\ntoken: \"${{ secrets.PAT || secrets.GITHUB_TOKEN }}\"\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n# Changelog Enforcer\n- name: Changelog Enforcer\nuses: dangoslen/changelog-enforcer@v3\nwith:\nchangeLogPath: \"CHANGELOG.md\"\nskipLabels: \"skip-changelog-check\"\n# Summary and status\n- run: echo \"\ud83c\udfa8 Changelog Enforcer quality checks completed\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre>"},{"location":"continuous-integration/github/workflows/practicalli/#clojure-lint-with-reviewdog","title":"Clojure Lint with Reviewdog","text":"<p>clj-kondo lint with reviewdog reports</p> <pre><code>---\n# Clojure Lint with clj-kondo and reviewdog\n#\n# Lint errors raised as comments on pull request conversation\nname: Lint Review\non: [pull_request]\njobs:\nclj-kondo:\nname: runner / clj-kondo\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n# Git Checkout\n- name: Checkout Code\nuses: actions/checkout@v3\nwith:\ntoken: \"${{ secrets.PAT || secrets.GITHUB_TOKEN }}\"\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n- name: clj-kondo\nuses: nnichols/clojure-lint-action@v2\nwith:\npattern: \"*.clj\"\nclj_kondo_config: \".clj-kondo/config-ci.edn\"\nlevel: \"error\"\nexclude: \".cljstyle\"\ngithub_token: ${{ secrets.github_token }}\nreporter: github-pr-review\n# Summary and status\n- run: echo \"\ud83c\udfa8 Lint Review checks completed\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre>"},{"location":"continuous-integration/github/workflows/practicalli/#clojure-quality-check","title":"Clojure quality check","text":"<ul> <li>clj-kondo syntax check for code and project configuration</li> <li>cljstyle code format check</li> <li>Kaocha unit test runner</li> </ul> <p>Clojure Quality Checks</p> <pre><code>---\nname: \"Clojure Quality Check\"\non:\npull_request:\npush:\nbranches:\n- main\njobs:\ntests:\nname: \"Clojure Quality Checks\"\nruns-on: ubuntu-latest\nsteps:\n# Git Checkout\n- name: Checkout Code\nuses: actions/checkout@v3\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n- name: \"Prepare Java runtime\"\nuses: actions/setup-java@v3\nwith:\ndistribution: \"temurin\"\njava-version: \"17\"\n- name: \"Cache Clojure Dependencies\"\nuses: actions/cache@v3\nwith:\npath: |\n~/.m2/repository\n~/.gitlibs\nkey: clojure-deps-${{ hashFiles('**/deps.edn') }}\nrestore-keys: clojure-deps-\n- name: \"Install Clojure tools\"\nuses: DeLaGuardo/setup-clojure@10\nwith:\ncli: 1.11.1.1165 # Clojure CLI\ncljstyle: 0.15.0 # cljstyle\nclj-kondo: 2022.10.05 # Clj-kondo\n# bb: 0.7.8           # Babashka\n- name: \"Lint with clj-kondo\"\nrun: clj-kondo --lint deps.edn src resources test --config .clj-kondo/config-ci.edn\n- name: \"Check Clojure Style\"\nrun: cljstyle check --report\n- name: \"Kaocha test runner\"\nrun: clojure -X:env/test:test/run\n</code></pre>"},{"location":"continuous-integration/github/workflows/practicalli/#mkdocs-publisher","title":"mkdocs publisher","text":"<p>A workflow used to publish Practicalli books.</p> <ul> <li><code>workflow_dispatch:</code> for manual trigger of workflow</li> <li><code>workflow_run:</code> to depend on a successful run of the <code>MegaLinter</code> workflow</li> <li><code>paths-ignore</code> defining paths to ignore changes from</li> <li>actions/setup-python installs python version 3</li> <li><code>pip</code> to install Material for MkDocs packages used for Practialli books</li> </ul> <p>MkDocs Publish Book workflow</p> <pre><code>---\nname: Publish Book\non:\n# Manually trigger workflow\nworkflow_dispatch:\n# Run work flow conditional on linter workflow success\nworkflow_run:\nworkflows:\n- \"MegaLinter\"\npaths-ignore:\n- README.md\n- CHANGELOG.md\n- .gitignore\nbranches:\n- main\ntypes:\n- completed\npermissions:\ncontents: write\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n- name: \"Checkout code\"\nuses: actions/checkout@v3\nwith:\nfetch-depth: 0\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- uses: actions/cache@v3\nwith:\nkey: ${{ github.ref }}\npath: .cache\n- run: pip install mkdocs-material mkdocs-callouts mkdocs-glightbox mkdocs-git-revision-date-localized-plugin mkdocs-redirects pillow cairosvg\n- run: mkdocs gh-deploy --force\n# Summary\n- run: echo \"\ud83c\udfa8 MkDocs book built and deployed to GitHub Pages\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre>"},{"location":"continuous-integration/github/workflows/practicalli/#scheduled-version-check","title":"Scheduled Version Check","text":"<p>Use liquidz/antq-action to check for new versions of Clojure libraries and GitHub action.</p> <p>The GtiHub action can use the following actions</p> <ul> <li><code>excludes:</code> list of space separated artefact names to exclude from the version check, use <code>groupId/artifactId</code> for Java libraries</li> <li><code>directories:</code> search paths to check, space separated.</li> <li><code>skips:</code> project types to skip to search, space separated. One of boot, clojure-cli, github-action, pom, shadow-cljs or leiningen.</li> </ul> <p><code>on: schedule: cron:</code> is used to set the frequency for running the workflow, using a POSIX cron syntax.</p> <p> GitHub Docs: GitHub Actions - schedule</p> <p>Scheduled Antq Version check with Manual Trigger</p> <pre><code>---\n# ------------------------------------------\n# Scheduled check of versions\n# - use as non-urgent report on versions\n# - Uses POSIX Cron syntax\n#   - Minute [0,59]\n#   - Hour [0,23]\n#   - Day of the month [1,31]\n#   - Month of the year [1,12]\n#   - Day of the week ([0,6] with 0=Sunday)\n#\n# Using liquidz/anta to check:\n# - GitHub workflows\n# - deps.edn\n# ------------------------------------------\nname: \"Scheduled Version Check\"\non:\nschedule:\n# - cron: \"0 4 * * *\" # at 04:04:04 ever day\n- cron: \"0 4 * * 5\" # at 04:04:04 ever Friday\n# - cron: \"0 4 1 * *\" # at 04:04:04 on first day of month\nworkflow_dispatch: # Run manually via GitHub Actions Workflow page\njobs:\nscheduled-version-check:\nname: \"Scheduled Version Check\"\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n- name: \"Checkout code\"\nuses: actions/checkout@v3\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n- name: \"Antq Version Check\"\nuses: liquidz/antq-action@main\nwith:\nexcludes: \"org.clojure/tools.deps.alpha\"\n# excludes: \"qualifier/libary-name groupId/artifactId\"\n# directories: \"search/path/1 search/path/2\"\n# skips: \"boot clojure-cli github-action pom shadow-cljs leiningen\"\n# Summary\n- run: echo \"\ud83c\udfa8 library versions checked with liquidz/antq\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre>"},{"location":"continuous-integration/github/workflows/system-catalog/","title":"System catalog","text":""},{"location":"continuous-integration/github/workflows/system-catalog/#backstageio","title":"Backstage.io","text":"<p>Backstage is an open platform for building developer portals, using a centralised software catalog.</p> <p>The Backstage Validator workflow checks the Backstage configuration of the current project.</p> <p>Validate Backstage.io configuration files</p> <pre><code>---\n# --- Validate Backstage.io configuration files ---#\n# https://github.com/marketplace/actions/backstage-entity-validator\n# trigger workflow if yaml files `.backstage/` directory updated\nname: Backstage Validator\non:\npull_request:\npaths:\n- \".backstage/\"\njobs:\n# Validate backstage configuration\nbackstage-validator:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- uses: RoadieHQ/backstage-entity-validator@v0.3.2\nwith:\npath: \".backstage/*.yaml\"\n</code></pre>"},{"location":"introduction/contributing/","title":"Contributing to Practicalli","text":"<p>Practicalli books are written in markdown and use MkDocs to generate the published website via a GitHub workflow.  MkDocs can also run a local server using the <code>make docs</code> target from the <code>Makefile</code></p> <p>By submitting content ideas and corrections you are agreeing they can be used in this workshop under the Creative Commons Attribution ShareAlike 4.0 International license.  Attribution will be detailed via GitHub contributors.</p> <p>All content and interaction with any persons or systems must be done so with respect and within the Practicalli Code of Conduct.</p>"},{"location":"introduction/contributing/#book-status","title":"Book status","text":""},{"location":"introduction/contributing/#submit-and-issue-or-idea","title":"Submit and issue or idea","text":"<p>If something doesnt seem quite right or something is missing from the book, please raise an issue via the GitHub repository explaining in as much detail as you can.</p> <p>Raising an issue before creating a pull request will save you and the maintainer time.</p>"},{"location":"introduction/contributing/#considering-a-pull-request","title":"Considering a Pull request?","text":"<p>Before investing any time in a pull request, please raise an issue explaining the situation.  This can save you and the maintainer time and avoid rejected pull requests.</p> <p>Please keep pull requests small and focused, as they are much quicker to review and easier to accept.  Ideally PR's should be for a specific page or at most a section.</p> <p>A PR with a list of changes across different sections will not be merged, it will be reviewed eventually though.</p>"},{"location":"introduction/contributing/#thank-you-to-everyone-that-has-contributed","title":"Thank you to everyone that has contributed","text":"<p>A huge thank you to Rich Hickey and the team at Cognitect for creating and continually guiding the Clojure language.  Special thank you to Alex Miller who has provided excellent advice on working with Clojure and the CLI tooling.</p> <p>The Clojure community has been highly supportive of everyone using Clojure and I'd like to thank everyone for the feedback and contributions.  I would also like to thank everyone that has joined in with the London Clojurins community, ClojureBridgeLondon, Clojurians Slack community, Clojurians Zulip community and Clojureverse community.</p> <p>Thank you to everyone who sponsors the Practicalli websites and videos and for the Clojurists Together sponsorship, it helps me continue the work at a much faster pace.</p> <p>Special thanks to Bruce Durling for getting me into Cloure in the first place.</p> <p></p>"},{"location":"introduction/writing-tips/","title":"Writing tips for MkDocs","text":"<p>Making the docs more engaging using the mkdocs-material theme reference guide</p> Configuring Colors <p>Material for MkDocs - Changing the colors lists the primary and accent colors available.</p> <p>HSL Color Picker for codes to modify the theme style, overriding colors in <code>docs/assets/stylesheets/extra.css</code></p>"},{"location":"introduction/writing-tips/#hypertext-links","title":"Hypertext links","text":"<p>Links open in the same browser window/tab by default.</p> <p>Add <code>{target=_blank}</code> to the end of a link to configure opening in a new tab</p> <pre><code>[link text](url){target=_blank}\n</code></pre>"},{"location":"introduction/writing-tips/#buttons","title":"Buttons","text":"<p>Convert any link into a button by adding <code>{.md-button}</code> class names to end of the markdown for a link, which uses <code>.md-button-primary</code> by default.  Include <code>target=_blank</code> for buttons with links to external sites.</p> <pre><code>[link text](http://practical.li/blog){.md-button target=_blank}\n</code></pre> <p>Or specify a different class</p> <pre><code>[link text](http://practical.li/blog){.md-button .md-button-primary}\n</code></pre> <p>Add an icon to the button</p> <p> Practicalli Issues  Practicalli Blog</p> <pre><code>[:fontawesome-brands-github: Practicalli Issues](http://practical.li/blog){ .md-button .md-button-primary }\n[:octicons-heart-fill-24: Practicalli Blog](http://practical.li/blog){ .md-button .md-button-primary }\n</code></pre> <p>Search all supported icons</p>"},{"location":"introduction/writing-tips/#youtube-video","title":"YouTube video","text":"<p>Use an iframe element to include a YouTube video, wrapping in a paragraph tag with center alignment to place the video in a centered horizontal position</p> <pre><code>&lt;p style=\"text-align:center\"&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/rQ802kSaip4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/p&gt;\n</code></pre> <p>mkdocs material does not have direct support for adding a YouTube video via markdown.</p>"},{"location":"introduction/writing-tips/#admonitions","title":"Admonitions","text":"<p>Supported admonition types</p> <p>Note</p> <p>Use <code>!!!</code> followed by <code>NOTE</code></p> <p>Adding a title</p> <p>Use <code>!!!</code> followed by <code>NOTE</code> and a <code>\"title in double quotes\"</code></p> <p>Shh, no title bar just the text... Use <code>!!!</code> followed by <code>NOTE</code> and a <code>\"\"</code> empty double quotes</p> <p>Abstract</p> <p>Use <code>!!!</code> followed by <code>ABSTRACT</code></p> <p>Info</p> <p>Use <code>!!!</code> followed by <code>INFO</code></p> <p>Tip</p> <p>Use <code>!!!</code> followed by <code>TIP</code></p> <p>Success</p> <p>Use <code>!!!</code> followed by <code>SUCCESS</code></p> <p>Question</p> <p>Use <code>!!!</code> followed by <code>QUESTION</code></p> <p>Warning</p> <p>Use <code>!!!</code> followed by <code>WARNING</code></p> <p>Failure</p> <p>Use <code>!!!</code> followed by <code>FAILURE</code></p> <p>Danger</p> <p>Use <code>!!!</code> followed by <code>DANGER</code></p> <p>Bug</p> <p>Use <code>!!!</code> followed by <code>BUG</code></p> <p>Example</p> <p>Use <code>!!!</code> followed by <code>EXAMPLE</code></p> <p>Quote</p> <p>Use <code>!!!</code> followed by <code>QUOTE</code></p>"},{"location":"introduction/writing-tips/#collapsing-admonitions","title":"Collapsing admonitions","text":"Note <p>Collapse those admonitions using <code>???</code> instead of <code>!!!</code></p> Replace with a title <p>Use <code>???</code> followed by <code>NOTE</code> and a <code>\"title in double quotes\"</code></p> Expanded by default <p>Use <code>???+</code>, note the <code>+</code> character,  followed by <code>NOTE</code> and a <code>\"title in double quotes\"</code></p>"},{"location":"introduction/writing-tips/#inline-blocks","title":"Inline blocks","text":"<p>Inline blocks of text to make a very specific callout within text</p> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Adding something to then end of text is probably my favourite</p> <p>Info</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"introduction/writing-tips/#code-blocks","title":"Code blocks","text":"<p>Code blocks include a copy icon automatically</p> <p>Syntax highlighting in code blocks</p> <pre><code>(defn my-function  ; Write a simple function\n\"With a lovely doc-string\"\n[arguments]\n(map inc [1 2 3]))\n</code></pre> <p>Give the code block a title using <code>title=\"\"</code> after the backtics and language name</p> src/practicalli/gameboard.clj<pre><code>(defn my-function\n\"With a lovely doc-string\"\n[arguments]\n(map inc [1 2 3]))\n</code></pre> <p>We all like line numbers, especially when you can set the starting line</p> src/practicalli/gameboard.clj<pre><code>(defn my-function\n\"With a lovely doc-string\"\n[arguments]\n(map inc [1 2 3]))\n</code></pre> <p>Add <code>linenums=42</code> to start line numbers from 42 onward</p> <pre><code>clojure linenums=\"42\" title=\"src/practicalli/gameboard.clj\"\n</code></pre>"},{"location":"introduction/writing-tips/#annotations","title":"Annotations","text":"<p>Annotations in a code block help to highlight important aspects.  Use the comment character for the language followed by a space and a number in brackets</p> <p>For example, in a shell code block, use <code># (1)</code> where 1 is the number of the annotation</p> <p>Use a number after the code block to add the text for the annotation, e.g. <code>1.</code>. Ensure there is a space between the code block and the annotation text.</p> <pre><code>ls -la $HOME/Downloads  # (1)\n</code></pre> <ol> <li> I'm a code annotation! I can contain <code>code</code>, formatted text, images, ... basically anything that can be written in Markdown.</li> </ol> <p>Code blocks with annotation, add <code>!</code> after the annotation number to suppress the <code>#</code> character</p> <pre><code>(defn helper-function\n\"Doc-string with description of function purpose\" ; (1)!\n[data]\n(merge {:fish 1} data)\n)\n</code></pre> <ol> <li>Always include a doc-string in every function to describe the purpose of that function, identifying why it was added and what its value is.</li> </ol> <p>GitHub action example with multiple annotations</p> <pre><code>name: ci # (1)!\non:\npush:\nbranches:\n- master # (2)!\n- main\npermissions:\ncontents: write\njobs:\ndeploy:\nruns-on: ubuntu-latest\nsteps:\n- uses: actions/checkout@v3\n- uses: actions/setup-python@v4\nwith:\npython-version: 3.x\n- run: pip install mkdocs-material # (3)!\n- run: mkdocs gh-deploy --force\n</code></pre> <ol> <li> <p>You can change the name to your liking.</p> </li> <li> <p>At some point, GitHub renamed <code>master</code> to <code>main</code>. If your default branch     is named <code>master</code>, you can safely remove <code>main</code>, vice versa.</p> </li> <li> <p>This is the place to install further [MkDocs plugins] or Markdown     extensions with <code>pip</code> to be used during the build:</p> <pre><code>pip install \\\nmkdocs-material \\\nmkdocs-awesome-pages-plugin \\\n...\n</code></pre> </li> </ol>"},{"location":"introduction/writing-tips/#highlight-lines-in-code-blocks","title":"Highlight lines in code blocks","text":"<p>Add highlight line meta data to a code block after the opening backticks and code block language.</p> <p><code>hl_lines=\"2\"</code> highlights line 2 in the codeblock</p> <pre><code>(defn my-function\n\"With a lovely doc-string\"\n[arguments]\n(map\ninc\n[1 2 3]))\n</code></pre>"},{"location":"introduction/writing-tips/#embed-external-files","title":"Embed external files","text":"<p><code>--8&lt;--</code> in a code block inserts code from a source code file or other text file</p> <p>Specify a local file from the root of the book project (the directory containing mkdocs.yml)</p> Scheduled Version Check GitHub Workflow from source code file scheduled version check<pre><code>---\n# ------------------------------------------\n# Scheduled check of versions\n# - use as non-urgent report on versions\n# - Uses POSIX Cron syntax\n#   - Minute [0,59]\n#   - Hour [0,23]\n#   - Day of the month [1,31]\n#   - Month of the year [1,12]\n#   - Day of the week ([0,6] with 0=Sunday)\n#\n# Using liquidz/anta to check:\n# - GitHub workflows\n# - deps.edn\n# ------------------------------------------\nname: \"Scheduled Version Check\"\non:\nschedule:\n# - cron: \"0 4 * * *\" # at 04:04:04 ever day\n# - cron: \"0 4 * * 5\" # at 04:04:04 ever Friday\n- cron: \"0 4 1 * *\" # at 04:04:04 on first day of month\nworkflow_dispatch: # Run manually via GitHub Actions Workflow page\njobs:\nscheduled-version-check:\nname: \"Scheduled Version Check\"\nruns-on: ubuntu-latest\nsteps:\n- run: echo \"\ud83d\ude80 Job automatically triggered by ${{ github.event_name }}\"\n- run: echo \"\ud83d\udc27 Job running on ${{ runner.os }} server\"\n- run: echo \"\ud83d\udc19 Using ${{ github.ref }} branch from ${{ github.repository }} repository\"\n- name: \"Checkout code\"\nuses: actions/checkout@v3\n- run: echo \"\ud83d\udc19 ${{ github.repository }} repository was cloned to the runner.\"\n- name: \"Antq Check versions\"\nuses: liquidz/antq-action@main\nwith:\nexcludes: \"\"\nskips: \"boot clojure-cli pom shadow-cljs leiningen\"\n# Summary\n- run: echo \"\ud83c\udfa8 library versions checked with liquidz/antq\"\n- run: echo \"\ud83c\udf4f Job status is ${{ job.status }}.\"\n</code></pre> Practicalli Project Templates Emacs project configuration - .dir-locals.el<pre><code>((clojure-mode . ((cider-preferred-build-tool . clojure-cli)\n                  (cider-clojure-cli-aliases . \":build:test/env:dev/reloaded\"))))\n</code></pre> <p>Code example reuse</p> <p>Use an embedded local or external file (URL) when the same content is required in more than one place in the book.</p> <p>An effective way of sharing code and configuration mutliple times in a book or across multiple books.</p>"},{"location":"introduction/writing-tips/#content-tabs","title":"Content tabs","text":"<p>Create in page tabs that can also be</p> <p>Setting up a project</p> Clojure CLILeiningen <pre><code>clojure -T:project/new :template app :name practicalli/gameboard\n</code></pre> <pre><code>lein new app practicalli/gameboard\n</code></pre> <p>Or nest the content tabs in an admonition</p> <p>Run a terminal REPL</p> Clojure CLILeiningen <pre><code>clojure -T:repl/rebel\n</code></pre> <pre><code>lein repl\n</code></pre>"},{"location":"introduction/writing-tips/#diagrams","title":"Diagrams","text":"<p>Neat flow diagrams</p> <p>Diagrams - Material for MkDocs</p> <pre><code>graph LR\n  A[Start] --&gt; B{Error?};\n  B --&gt;|Yes| C[Hmm...];\n  C --&gt; D[Debug];\n  D --&gt; B;\n  B ----&gt;|No| E[Yay!];</code></pre> <p>UML Sequence Diagrams</p> <pre><code>sequenceDiagram\n  Alice-&gt;&gt;John: Hello John, how are you?\n  loop Healthcheck\n      John-&gt;&gt;John: Fight against hypochondria\n  end\n  Note right of John: Rational thoughts!\n  John--&gt;&gt;Alice: Great!\n  John-&gt;&gt;Bob: How about you?\n  Bob--&gt;&gt;John: Jolly good!</code></pre> <p>state transition diagrams</p> <pre><code>stateDiagram-v2\n  state fork_state &lt;&lt;fork&gt;&gt;\n    [*] --&gt; fork_state\n    fork_state --&gt; State2\n    fork_state --&gt; State3\n\n    state join_state &lt;&lt;join&gt;&gt;\n    State2 --&gt; join_state\n    State3 --&gt; join_state\n    join_state --&gt; State4\n    State4 --&gt; [*]</code></pre> <p>Class diagrams - not needed for Clojure</p> <p>Entity relationship diagrams are handy though</p> <pre><code>erDiagram\n  CUSTOMER ||--o{ ORDER : places\n  ORDER ||--|{ LINE-ITEM : contains\n  LINE-ITEM {\n    customer-name string\n    unit-price int\n  }\n  CUSTOMER }|..|{ DELIVERY-ADDRESS : uses</code></pre>"},{"location":"introduction/writing-tips/#keyboard-keys","title":"Keyboard keys","text":"<p>Represent key bindings with Keyboard keys. Each number and alphabet character has their own key.</p> <ul> <li>1 <code>++1++</code> for numbers</li> <li>l <code>++\"l\"++</code> for lowercase character</li> <li>U <code>++u++</code> for uppercase character or <code>++\"U\"++</code> for consistency</li> </ul> <p>Punctionation keys use their name</p> <ul> <li>Space <code>++spc++</code></li> <li>, <code>++comma++</code></li> <li>Left <code>++arrow-left++</code></li> </ul> <p>For key sequences, place a space between each keyboard character</p> <ul> <li>Space g s <code>++spc++ ++\"g\"++ ++\"s\"++</code></li> </ul> <p>For key combinations, use join they key identifies with a <code>+</code></p> <ul> <li>Meta+X <code>++meta+x++</code></li> <li>Ctrl+Alt+Del <code>++ctrl+alt+del++</code></li> </ul> <p>MkDocs keyboard keys reference</p>"},{"location":"introduction/writing-tips/#images","title":"Images","text":"<p>Markdown images can be appended with material tags to set the size of the image, whether to appear on light or dark theme and support lazy image loading in browsers</p> SizeLazy LoadingAlignTheme SpecificAll Image Attributes <p><code>{style=\"height:150px;width:150px\"}</code> specifies the image size <pre><code>![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-light.png#only-dark){style=\"height:150px;width:150px\"}\n</code></pre></p> <p></p> <p><code>{loading=lazy}</code> specifies an image should lazily load in the browser <pre><code>![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-light.png){loading=lazy}\n</code></pre></p> <p><code>{aligh=left}</code> or <code>{aligh=right}</code> specifies the page alignment of an image. <pre><code>![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-light.png#only-dark){align=right}\n![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-dark.png#only-light){align=right}\n</code></pre></p> <p>  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p> <p><code>![Kitty Logo](image/kitty-light.png#only-dark)</code> or <code>![Kitty Logo](image/kitty-light.png#only-light)</code>  specifies the theme the image should be shown, allowing different versions of images to be shown based on the theme. <pre><code>![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-light.png#only-dark){style=\"height:150px;width:150px\"}\n![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-dark.png#only-light){style=\"height:150px;width:150px\"}\n</code></pre> Use the theme toggle in the top nav bar to see the icon change between light and dark.  </p> <p>Requires the color pallet toggle</p> <p>Alight right, lazy load and set image to 150x150</p> <pre><code>![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-light.png#only-dark){align=right loading=lazy style=\"height:64px;width:64px\"}\n![Kitty Logo](https://raw.githubusercontent.com/practicalli/graphic-design/live/icons/kitty-dark.png#only-light){align=right loading=lazy style=\"height:64px;width:64px\"}\n</code></pre> <p>  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"introduction/writing-tips/#lists","title":"Lists","text":"<p>Task lists</p> <ul> <li> Lorem ipsum dolor sit amet, consectetur adipiscing elit</li> <li> Vestibulum convallis sit amet nisi a tincidunt<ul> <li> In hac habitasse platea dictumst</li> <li> In scelerisque nibh non dolor mollis congue sed et metus</li> <li> Praesent sed risus massa</li> </ul> </li> <li> Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque</li> </ul> <p>Task List example</p> <pre><code>- [x] Lorem ipsum dolor sit amet, consectetur adipiscing elit\n- [ ] Vestibulum convallis sit amet nisi a tincidunt\n    * [x] In hac habitasse platea dictumst\n    * [x] In scelerisque nibh non dolor mollis congue sed et metus\n    * [ ] Praesent sed risus massa\n- [ ] Aenean pretium efficitur erat, donec pharetra, ligula non scelerisque\n</code></pre>"},{"location":"introduction/writing-tips/#tooltips","title":"Tooltips","text":"<p>The humble tool tip</p> <p>Hover me</p> <p>with references</p> <p>Hover me</p> <p>Icon tool tip with a title</p> <p></p>"},{"location":"introduction/writing-tips/#abreviations","title":"Abreviations","text":"<p>The HTML specification is maintained by the W3C.</p> <p>[HTML]: Hyper Text Markup Language [W3C]: World Wide Web Consortium</p>"},{"location":"introduction/writing-tips/#magic-links","title":"Magic links","text":"<p>MagicLink can auto-link HTML, FTP, and email links. It can auto-convert repository links (GitHub, GitLab, and Bitbucket) and display them in a more concise, shorthand format.</p> <p>Email Practicalli</p> <p>Practicalli Neovim</p>"},{"location":"practices/","title":"Engineering Practices","text":"<p>Engineering has many practices and principles defined over it many decades.</p> <ul> <li> <p>Agile software Development</p> <ul> <li>Agile Manifesto</li> <li>Extreme Programming</li> <li>Test Driven Development</li> <li>Retrospective</li> </ul> </li> <li> <p>Lean software development</p> </li> <li> <p>Kanban</p> </li> <li> <p>Behaviour Driven Development</p> </li> <li> <p>General Project Management techniques</p> <ul> <li>Rolling Wave Planning</li> <li>MoSCow rules - Must Have, Should Have, Could Have</li> </ul> </li> </ul>"},{"location":"practices/behaviour-driven-development/","title":"Behaviour Driven Development","text":"<p>Behaviour-driven development (BDD) is an evolution of the ideas behind agile software delivery. With its roots in test-driven development, domain-driven design, and automated acceptance testing, BDD focuses on the ways an application is expected to work - its behaviour.</p> <p>Understanding your domain and who your stakeholders are, identifying and exploring requirements, automating acceptance criteria, and delivering working and tested software.</p> <p>BDD is writing software that matters</p> <p>Introducing BDD - Dan North</p>"},{"location":"practices/behaviour-driven-development/#bdd-concepts","title":"BDD concepts","text":"Concept Description Outside-in understand system usage from the outside (user interfaces) inwards Pull based system Produce only that which is ready to be used by people, systems, or code closer to a boundary or UI Multiple stakeholder Core and incidental stakeholders - Core stakeholders define the vision and often provide budget; Incidental stakeholders support the solution delivery and may influence that solution Multiple scale BDD applied from end to end, from small feature set to enterprise projects High automation Automation of testing (acceptance &amp; unit) hence reducing the expense of scenario and examples testing; Enabling and inviting change through acceptance tests and reducing the impact of change Features A slice through the whole solution; defined by multiple scenarios describing interactions stemming from user interface (outside-in). Features are defined with respect to business value Feature Injection Only work on features that deliver value, according to the project vision/goals (in the context of the organisations goals) Ubiquitous language Using the language of the domain consistently, end to end in the solution artefacts; name things with respect to their behavior in the domain. Using Given,When,Then also provides structure to the ubiquitous language"},{"location":"practices/behaviour-driven-development/#example-exercise","title":"Example Exercise","text":"<p>This is a BDD style description of the case study requirements for the service called Boris Bikes.</p> <p>The scenarios give you ideas of behaviour you should consider when trying to implement the case study in a Test Driven Development approach.</p> <p>Pick a scenario and write one or more tests that will satisfy that scenario.</p> <p>The Features here are not necessarily in line with the scenarios, please feel free to create new features that are more relevant.</p> <p>City Bike Hire Service</p> <pre><code>Feature: City Bikes Service\n  In order to provide a convenient way to get around the City of London\n  As the Mayor of a city\n  I want to provide a bike hire service\n\n  Scenario: scenario name\n    Given .\n    When .\n    Then .\n\nFeature: Commute around the city quickly\n  In order to get around London quickly\n  As a commuter tired of using the tube (and tube strikes)\n  I want to hire a bike to get me around central London\n\n  Scenario: Hire a bike\n    Given there is a bike available for hire\n    When I identify myself to the bike hire station\n    Then I get access to the bike\n\n  Scenario: Return a bike\n    Given I have taken a bike for hire\n    When I identify myself to the bike hire station\n    And return the bike correctly\n    Then my bike hire ends\n    And payment is taken\n\n  Scenario: Find a parking slot\n    Given I have taken a bike for hire\n    And my current bike station has no free slots\n    When I ask the hire station for available slots\n    Then I get the number of slots for the 3 nearest bike stations\n\n  Scenario: Register\n    Given .\n    When .\n    Then .\n\n  Scenario: Identify myself as a registered user\n    Given I am a regular rider\n    When I hire a bike\n    Then I use my key at the bike station to identify myself\n\n  Scenario: See if a particular bike station has bikes\n    Given .\n    When .\n    Then .\n\n  Scenario: Find nearest location with available bikes\n    Given .\n    When .\n    Then .\n\n  Scenario: Book a bike in advance\n    Given .\n    When .\n    Then .\n</code></pre>"},{"location":"practices/behaviour-driven-development/#references","title":"References","text":"<p>Introducing BDD - Dan North Cucumber - Behaviour Driven Development Behaviour Driven Development - Wikipedia</p>"},{"location":"practices/deliberate-practice/","title":"Deliberate Practice","text":"<p>We learn by doing, but we need to do something many times before it becomes instinctive or ingrained.  Deliberate practice is about doing something in order to learn rather than produce a finished product</p> <p>In studies of accomplished individuals, researchers have found few signs of precocious achievement before the individuals started intensive training. Similar findings have turned up in studies of musicians, tennis players, artists, swimmers, mathematicians, and others.</p> <p>Deliberate practice is a specific and unique kind of activity, neither work nor play. It\u2019s characterised by several elements that together form a powerful whole.</p> <p>Most fundamentally, what we generally do\u2026. isn\u2019t designed by anyone to make us better at anything. Usually it isn\u2019t designed at all: We are just given an objective that\u2019s necessary to meeting the employer\u2019s goals and then expected to get on with it.</p> <p>Working on a software project under deadlines and other pressures detracts from what you can learn, unless you take the time to setp back from the \"doing\" and \"deadline\".  Coding dojo and coding kata are not aimed at being an effective way to develop a software product, they are training tools to help you learn and improve your skills effectively.</p> <p>By attending a coding dojo on a regular basis will gain a lot of experiences that will help you become more effective when working on projects.  A coding dojo helps developers become comfortable with pair programming, and helps pair programming and promiscuous pairing happen at work.  At a coding dojo you will also lean a great deal from the practical experience of others, things that people forget they know or do almost instinctively.</p>"},{"location":"practices/deliberate-practice/#code-kata","title":"Code Kata","text":"<p>Coding Kata A coding kata is a small coding exercise that you repeat over and over again, helping you improve your coding skills.</p> <p>The kata is not about producing a usable solution as this detracts from the learning experience.</p> <p>A coding kata for a developer is like an athlete doing warming up exercises before a run.</p> <p>A coding kata is often used to warm up your skills before you start work each day.  Working on a kata problem that is not related to any of your work allows you to think about how you write code rather than thinking of delivery and meeting estimates.</p> <p>Coding kata's normally use a test first approach, as in TDD.</p> <p> Kata Challenges - Practicalli Clojure</p> <p>Coding Dojo website</p> <p>Randori - Wikipedia</p>"},{"location":"practices/deliberate-practice/#prepared-kata","title":"Prepared Kata","text":"<p>A presenter shows how to solve a challenge using TDD using baby steps</p> <p>Each step must make sense to everyone present</p> <p>Audience only interrupts if something is not understood.</p>"},{"location":"practices/deliberate-practice/#code-dojo","title":"Code Dojo","text":"<p>A coding dojo is a group event to help you learn a language, a framework or development technique.</p> <p>At the coding dojo, a laptop is connected to a projector so everyone can see the coding taking place.</p> <p>At regular intervals, one pilot and one co-pilot take there positions at the computer and have a set time to create a new test, implement code to fix a failing test or refactor the code.</p> <p>The pilot writes tests or code whilst the co-pilot asks questions and discusses the approach they are taking.</p> <p>If the pilot and co-pilot need help, they can ask the audience for guidance.</p>"},{"location":"practices/deliberate-practice/#further-thoughts","title":"Further thoughts","text":"<p>Deliberate practice is designed specifically to improve performance with the key word being \u2018designed.\u2019 The essence of deliberate practice is continually stretching an individual just beyond his or her current abilities. By contrast, deliberate practice requires that one identify certain sharply defined elements of performance that need to be improved, and then work intently on them. The great performers isolate remarkably specific aspects of what they do and focus on just those things until they\u2019re improved; then it\u2019s on to the next aspect.</p> <p>Deliberate practice can be repeated. High repetition is the most important difference between deliberate practice of a task and performing the task for real, when it counts. One is the choice of a properly demanding activity just beyond our current abilities. The other is the amount of repetition.\"</p> <p>Feedback on results is continuously available. Though this is obvious, it is not nearly as simple as it might seem, especially when results require interpretation. In many important situations, a teacher, coach, or mentor is vital for providing crucial feedback.</p> <p>It\u2019s highly demanding mentally. Deliberate practice is above all an effort of focus and concentration. That is what makes it \u2018deliberate.\u2019 Continually seeking exactly those elements of performance that are unsatisfactory and then trying one\u2019s hardest to make them better places enormous strains on anyone\u2019s mental abilities. The work is so great that it seems no one can sustain it for very long.</p> <p>It\u2019s hard. This follows inescapably from the other characteristics of deliberate practice, which could be described as a recipe for not having fun. Doing things we know how to do well is enjoyable, and that\u2019s exactly the opposite of what deliberate practice demands. Instead of doing what we\u2019re good at, we insistently seek out what we\u2019re not good at.</p> <p>There is a definitive \u2018before the work\u2019 component. Self-regulation begins with setting goals \u2013 not big, life-directing goals, but more immediate goals for what you\u2019re going to be doing today. In the research, the poorest performers don\u2019t set goals at all; they just slog through their work. Mediocre performers set goals that are general and are often focused on simply achieving a good outcome. The best performers set goals that are not about the outcome but rather about the process of reaching the outcome.</p> <p>There is a \u2018during the work\u2019 phase. The most important self-regulatory skill that top performers in every field use during their work is self-observation. Even in purely mental work, the best performers observe themselves closely. They are able to monitor what is happening in their own minds and ask how it\u2019s going. Researchers call this metacognition \u2013 knowledge about your own knowledge, thinking about your own thinking. Top performers do this much more systematically than others do; it\u2019s an established part of their routine.</p> <p>There is an \u2018after the work\u2019 component as well. Practice activities are worthless without useful feedback about the results. These must be self-evaluations and the best performers judge themselves against a standard that\u2019s relevant for what they\u2019re trying to achieve. Sometimes they compare their performance with their own personal best; sometimes they compare it with the performance of competitors they\u2019re facing or expect to face; sometimes they compare it with the best known performance by anyone in the field.</p>"},{"location":"technical-writing/","title":"Technical writing","text":""},{"location":"technical-writing/#website-generators","title":"Website generators","text":"<p>Static web sites are fast to serve and relatively low maintenance, so can make for an excellent approach to serving up technical documentation.</p>"},{"location":"technical-writing/#clojure-tech-docs","title":"Clojure tech docs","text":"<p>cljdoc</p> <p>cljdoc is a website building &amp; hosting documentation for Clojure/Script libraries</p>"},{"location":"technical-writing/#tips","title":"Tips","text":"<ul> <li>learn English grammar</li> <li>avoid English pronouns, pronouns are often an indicator of verbosity</li> </ul>"}]}